[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Working on HPC Clusters using SLURM",
    "section": "",
    "text": "Overview\nKnowing how to work on a High Performance Computing (HPC) system is an essential skill for applications such as bioinformatics, big-data analysis, image processing, machine learning, parallelising tasks, and other high-throughput applications.\nThese materials give a practical overview of working on HPC servers, with a particular focus on submitting and monitoring jobs using a job scheduling software. We focus on the job scheduler SLURM, although the concepts covered are applicable to other commonly used job scheduling software. This is a hands-on workshop, which should be accessible to researchers from a range of backgrounds and offering several opportunities to practice the skills we learn along the way.\nBy the end of this course you will be able to independently work on a typical HPC server.",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Working on HPC Clusters using SLURM",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nDescribe how a HPC cluster is typically organised and how it differs from a regular computer.\nRecognise the tasks that a HPC cluster is suitable for.\nAccess and work on a HPC server.\nSubmit and manage jobs running on a HPC.\nParalelise similar tasks at scale.\nAccess, install and manage software on a HPC.",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#target-audience",
    "href": "index.html#target-audience",
    "title": "Working on HPC Clusters using SLURM",
    "section": "Target Audience",
    "text": "Target Audience\nThis course is aimed at students and researchers of any background. We assume no prior knowledge of what a HPC is or how to use it.\nIt may be particularly useful for those who have attended other of our Bioinformatics Training Courses and now need to process their data on a Linux server. It will also benefit those who find themselves using their personal computers to run computationally demanding analysis/simulations and would like to learn how to adapt these to run on a HPC.",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Working on HPC Clusters using SLURM",
    "section": "Prerequisites",
    "text": "Prerequisites\nWe assume a solid knowledge of the Unix command line. If you don’t feel comfortable with the command line, please attend our accompanying Introduction to the Unix Command Line course.\nNamely, we expect you to be familiar with the following:\n\nNavigate the filesystem: pwd (where am I?), ls (what’s in here?), cd (how do I get there?)\nInvestigate file content using utilities such as: head/tail, less, cat/zcat, grep\nUsing “flags” to modify a program’s behaviour, for example: ls -l\nRedirect output with &gt;, for example: echo \"Hello world\" &gt; some_file.txt\nUse the pipe | to chain several commands together, for example ls | wc -l\nExecute shell scripts with bash some_script.sh",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#authors",
    "href": "index.html#authors",
    "title": "Working on HPC Clusters using SLURM",
    "section": "Authors",
    "text": "Authors\nPlease cite these materials if:\n\nYou adapted or used any of them in your own teaching.\nThese materials were useful for your research work. For example, you can cite us in the methods section of your paper: “We carried our analyses based on the recommendations in YourReferenceHere”.\n\n\nYou can cite these materials as:\n\nTavares, H., Kalmár, L. (2024). Working on HPC Clusters using SLURM. https://cambiotraining.github.io/hpc-intro\n\nOr in BibTeX format:\n@misc{YourReferenceHere,\n  author = {Tavares, Hugo and Kalmár, Lajos},\n  month = {9},\n  title = {Working on HPC Clusters using SLURM},\n  url = {https://cambiotraining.github.io/hpc-intro},\n  year = {2024}\n}\nAbout the authors:\nHugo Tavares  \nAffiliation: Cambridge Centre for Research Informatics Training Roles: writing - original draft; conceptualisation; software\n\nLajos Kalmár  \nAffiliation: MRC Toxicology Unit, University of Cambridge Roles: conceptualisation; software",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Working on HPC Clusters using SLURM",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\n\nThanks to Qi Wang (Department of Plant Sciences, University of Cambridge) for constructive feedback and ideas in the early iterations of this course.\nThanks to @Alylaxy for his pull requests to the repo (#34).\nThanks to the HPC Carpentry community for developing similar content.",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Data & Setup",
    "section": "",
    "text": "Software\nThere are three recommended pieces of software needed to work with the HPC:\nThis document gives instructions on how to install or access these on different operating systems.",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data & Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#software",
    "href": "setup.html#software",
    "title": "Data & Setup",
    "section": "",
    "text": "a terminal\na file transfer software\na text editor with the ability to edit files on a remote server\n\n\n\nUnix terminal\n\nWindowsmacOSLinux\n\n\nIf you are comfortable with installing software on your computer, we highly recommend installing the Windows Subsystem for Linux (WSL2), which provides native Linux functionality from within Windows.\nAlternatively, you can install MobaXterm, which provides a Unix-like terminal on Windows.\nWe provide instructions for both.\n\nMobaXtermWSL\n\n\n\nGo the the MobaXterm download page.\nDownload the “Portable edition” (blue button).\n\nUnzip the downloaded file and copy the folder to a convenient location, such as your Desktop.\nYou can directly run the program (without need for installation) from the executable in this folder.\n\n\nYou can access your Windows files from within MobaXterm. Your C:\\ drive is located in /drives/C/ (equally, other drives will be available based on their letter). For example, your documents will be located in: /drives/C/Users/&lt;WINDOWS USERNAME&gt;/Documents/. By default, MobaXterm creates shortcuts for your Windows Documents and Desktop.\nIt may be convenient to set shortcuts to other commonly-used directories, which you can do using symbolic links. For example, to create a shortcut to Downloads: ln -s /drives/C/Users/&lt;WINDOWS USERNAME&gt;/Downloads/ ~/Downloads\n\n\nThere are detailed instructions on how to install WSL on the Microsoft documentation page. But briefly:\n\nClick the Windows key and search for Windows PowerShell, right-click on the app and choose Run as administrator.\nAnswer “Yes” when it asks if you want the App to make changes on your computer.\nA terminal will open; run the command: wsl --install.\n\nThis should start installing “ubuntu”.\nIt may ask for you to restart your computer.\n\nAfter restart, click the Windows key and search for Ubuntu, click on the App and it should open a new terminal.\nFollow the instructions to create a username and password (you can use the same username and password that you have on Windows, or a different one - it’s your choice).\nYou should now have access to a Ubuntu Linux terminal. This (mostly) behaves like a regular Ubuntu terminal, and you can install apps using the sudo apt install command as usual.\n\nAfter WSL is installed, it is useful to create shortcuts to your files on Windows. Your C:\\ drive is located in /mnt/c/ (equally, other drives will be available based on their letter). For example, your desktop will be located in: /mnt/c/Users/&lt;WINDOWS USERNAME&gt;/Desktop/. It may be convenient to set shortcuts to commonly-used directories, which you can do using symbolic links, for example:\n\nDocuments: ln -s /mnt/c/Users/&lt;WINDOWS USERNAME&gt;/Documents/ ~/Documents\n\nIf you use OneDrive to save your documents, use: ln -s /mnt/c/Users/&lt;WINDOWS USERNAME&gt;/OneDrive/Documents/ ~/Documents\n\nDesktop: ln -s /mnt/c/Users/&lt;WINDOWS USERNAME&gt;/Desktop/ ~/Desktop\nDownloads: ln -s /mnt/c/Users/&lt;WINDOWS USERNAME&gt;/Downloads/ ~/Downloads\n\n\n\n\n\n\nMac OS already has a terminal available.\nPress ⌘ + space to open spotlight search and type “terminal”.\nOptionally, if you would like a terminal with more modern features, we recommend installing iTerm2.\n\n\nLinux distributions already have a terminal available.\nOn Ubuntu you can press Ctrl + Alt + T to open it.\n\n\n\n\n\nFilezilla\n\nWindowsmacOSLinux\n\n\n\nGo to the Filezilla Download page and download the file FileZilla_3.65.0_win64-setup.exe (the latest version might be slightly different). Double-click the downloaded file to install the software, accepting all the default options.\nAfter completing the installation, go to your Windows Menu, search for “Filezilla” and launch the application, to test that it was installed successfully.\n\n\n\n\nGo to the Filezilla Download page and download either the macOS (Intel) (for older processors) or macOS (Apple Silicon) (for newer M* processors) installers.\nGo to the Downloads folder and double-click the file you just downloaded to extract the application. Drag-and-drop the “Filezilla” file into your “Applications” folder.\nYou can now open the installed application to check that it was installed successfully (the first time you launch the application you will get a warning that this is an application downloaded from the internet - you can go ahead and click “Open”).\n\n\n\n\nFilezilla often comes pre-installed in major Linux distributions such as Ubuntu. Search your applications to check that it is installed already.\nIf it is not, open a terminal and run:\n\nUbuntu: sudo apt-get update && sudo apt-get install filezilla\nCentOS: sudo yum -y install epel-release && sudo yum -y install filezilla\n\n\n\n\n\n\n\nVisual Studio Code (optional)\n\nWindowsmacOSLinux\n\n\n\nGo to the Visual Studio Code download page and download the installer for your operating system. Double-click the downloaded file to install the software, accepting all the default options.\nAfter completing the installation, go to your Windows Menu, search for “Visual Studio Code” and launch the application.\nGo to “File &gt; Preferences &gt; Settings”, then select “Text Editor &gt; Files” on the drop-down menu on the left. Scroll down to the section named “EOL” and choose “\\n” (this will ensure that the files you edit on Windows are compatible with the Linux operating system).\nContinue by following the instructions “Configuring Visual Studio Code”.\n\n\n\n\nGo to the Visual Studio Code download page and download the installer for Mac.\nGo to the Downloads folder and double-click the file you just downloaded to extract the application. Drag-and-drop the “Visual Studio Code” file to your “Applications” folder.\nYou can now open the installed application to check that it was installed successfully (the first time you launch the application you will get a warning that this is an application downloaded from the internet - you can go ahead and click “Open”).\nContinue by following the instructions “Configuring Visual Studio Code”.\n\n\n\n\nGo to the Visual Studio Code download page and download the installer for your Linux distribution. Install the package using your system’s installer.\nContinue by following the instructions in “Configuring Visual Studio Code”.\n\n\n\n\n\nConfiguring Visual Studio Code\nWe will use an extension called “Remote-SSH”. To install the extension (see Figure 2.1):\n\nClick the “Extensions” button on the side bar (or use Ctrl + Shift + X).\nIn the search box type “remote ssh” and choose the “Remote - SSH” extension.\nClick the “Install” button in the window that opens.\nRestart VS Code.\nGo to File → Preferences → Settings\nIn the search box type “Remote SSH: Show Login Terminal”\nTick the option “Always reveal the SSH login terminal”\n\n\n\n\n\n\n\nFigure 2.1: Installing Remote-SSH extension in VS Code",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data & Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#data",
    "href": "setup.html#data",
    "title": "Data & Setup",
    "section": "Data",
    "text": "Data\nIf you are attending our workshop, then all the data is already provided on our training HPC. However, if you want to practice after the course on your HPC, you can download the data and scripts used in the exercises from the links below.\nNote the two versions below are very similar, some SLURM options are different depending on our training environment, but for practicing in your own HPC it won’t make a difference, as you will have to change the SLURM options regardless.\n\nGenericCSD3\n\n\n  Download \nProgrammatically, you can do:\n# generic version\nwget -O data.zip \"https://www.dropbox.com/scl/fo/5s692xhuoux7yc7r6r2pt/AKuJpv5dfP3-mdNiD_mxfvk?rlkey=ui0tjjhlwyx2gns2auugw1qlj&st=y6a2m392&dl=1\"\nunzip data.zip -d DIRECTORY_OF_YOUR_CHOICE\n\n\n  Download \nProgrammatically, you can do:\n# CSD3 version\nwget -O data.zip \"https://www.dropbox.com/scl/fo/c87w8w50fvw0vqrf4daiw/AGLNUyI6H7_kS2zdBwPSais?rlkey=j1dfqqb39sfnxffmnu953r19z&st=93ya9s80&dl=1\"\nunzip data.zip -d ~/rds/hpc-work/hpc_workshop",
    "crumbs": [
      "Slides",
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data & Setup</span>"
    ]
  },
  {
    "objectID": "materials/01-intro.html",
    "href": "materials/01-intro.html",
    "title": "3  HPC Introduction",
    "section": "",
    "text": "3.1 What is a HPC and what are its uses?\nHPC stands for High-Performance Computing and refers to the use of powerful computers and programming techniques to solve computationally-intensive tasks. Very often, several of these high-performance computers are connected together in a network and work as a unified system, forming a HPC cluster. HPC clusters typically consist of numerous nodes (computers) connected through a high-speed network, and they are used to distribute and parallelise tasks.\nThe main usage of HPC clusters is to run resource-intensive and/or parallel tasks. For example: running thousands of simulations, each one taking several hours; assembling a genome from sequencing data, which requires computations on large volumes of data in memory. These tasks would be extremely challenging to complete on a regular computer. However, they are just the kind of task that a HPC would excel at.\nWhen working on a HPC it is important to understand what kinds of resources are available to us. These are the main resources we need to consider:\nUsually, HPC servers are available to members of large institutions (such as a Universities or research institutes) or sometimes from cloud providers. This means that:\nSo, at any one time, across all the users, there might be many thousands of processes running on the HPC! There has to be a way to manage all this workload, and this is why HPC clusters are typically organised somewhat differently from what we might be used to when we work on our own computers. Figure 1 shows a schematic of a HPC, and we go into its details in the following sections.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>HPC Introduction</span>"
    ]
  },
  {
    "objectID": "materials/01-intro.html#what-is-a-hpc-and-what-are-its-uses",
    "href": "materials/01-intro.html#what-is-a-hpc-and-what-are-its-uses",
    "title": "3  HPC Introduction",
    "section": "",
    "text": "NoteTerminology\n\n\n\nThe terms HPC and cluster are often used interchangeably to mean the same thing (a “HPC cluster”). Technically they mean different things, but for practical reasons we use either term throughout these materials.\n\n\n\n\nCPU (central processing units) is the “brain” of the computer, performing a wide range of operations and calculations. CPUs can have several “cores”, which means they can run tasks in parallel, increasing the throughput of calculations per second. A typical personal computer may have a CPU with 4-8 cores. A single compute node on the HPC may have 32-48 cores (and often these are faster than the CPU on our computers).\nRAM (random access memory) is a quick access storage where data is temporarily held while being processed by the CPU. A typical personal computer may have 8-32Gb of RAM. A single compute nodes on a HPC may often have &gt;100Gb RAM.\nGPUs (graphical processing units) are similar to CPUs, but are more specialised in the type of operations they can do. While less flexible than CPUs, each GPU can do thousands of calculations in parallel. This makes them extremely well suited for graphical tasks, but also more generally for matrix computations and so are often used in machine learning applications.\n\n\n\nThere are many users, who may simultaneously be using the HPC.\nEach user may want to run several jobs concurrently.\nOften large volumes of data are being processed and there is a need for high-performance storage (allowing fast read-writting of files).\n\n\n\n\n\n\n\n\nFigure 3.1: Organisation of a typical HPC.\n\n\n\n\n3.1.1 Nodes\nThere are two types of nodes on a cluster (Figure 3.1):\n\nlogin nodes (also known as head or submit nodes).\ncompute nodes (also known as worker nodes).\n\nThe login nodes are the computers that the user connects to and from where they interact with the cluster. Depending on the size of the cluster, there is often only one login node, but larger clusters may have several of them. Login nodes are used to interact with the filesystem (move around the directories), download and move files, edit and/or view text files and doing other small routine tasks.\nThe compute nodes are the machines that will actually do the hard work of running jobs. These are often high-spec computers with many CPUs and high RAM (or powerful GPU cards), suitable for computationally demanding tasks. Often, there are several “flavours” of compute nodes on the same cluster. For example some compute nodes may have fewer CPUs but higher memory (suitable for memory-intensive tasks), while others may have the opposite (suitable for highly-parallelisable tasks).\nUsers do not have direct access to the compute nodes and instead submitting jobs via a job scheduler.\n\n\n3.1.2 Job Scheduler\nA job scheduler is a software used to submit commands to be run on the compute nodes (orange box in Figure 3.1). This is needed because there may often be thousands of processes that all the users of the HPC want to run at any one time. The job scheduler’s role is to manage all these jobs, so you don’t have to worry about it.\nWe will cover the details of how to use a job scheduler in “Using a Job Scheduler”. For now, it is enough to know that, using the job scheduler, the user can request specific resources to run their job (e.g. number of cores, RAM, how much time we want to reserve the compute node to run our job, etc.). The job scheduler software then takes care of considering all the jobs being submitted by all the users and putting them in a queue until there are compute nodes available to run the job with the requested resources.\n\n\n\n\n\n\nFigure 3.2: An analogy of the job scheduler as a porter in a restaurant, who checks the groups of people in the queue and assigns them a seat depending on the size of the group and how long they might stay for dinner.\n\n\n\nIn terms of parallelising calculations, there are two ways to think about it, and which one we use depends on the specific application. Some software packages have been developed to internally parallelise their calculations (or you may write your own script that uses a parallel library). These are very commonly used in bioinformatic applications, for example. In this case we may want to submit a single job, requesting several CPU cores for it.\nIn other cases, we may have a program that does not parallelise its calculations, but we want to run many iterations of it. A typical example is when we want to run simulations: each simulation only uses a single core, but we want to run thousands of them. In this case we would want to submit each simulation as a separate job, but only request a single CPU core for each job.\nFinally, we may have a case where both of these are true. For example, we want to process several data files, where each data file can be processed using tools that parallelise their calculations. In this case we would want to submit several jobs, requesting several CPU cores for each.\n\n\n\n\n\n\nNote\n\n\n\nJob Schedulers\nThere are many job scheduler programs available, in this course we will cover one called SLURM, but other common ones include LSF, PBS, HT Condor, among others.\n\n\n\n\n3.1.3 Filesystem\nThe filesystem on a HPC cluster often consists of storage partitions that are shared across all the nodes, including both the login and compute nodes (green box in Figure 1). This means that data can be accessed from all the computers that compose the HPC cluster.\nAlthough the filesystem organisation may differ depending on the institution, typical HPC servers often have two types of storage:\n\nThe user’s home directory (e.g. /home/user) is the default directory that one lands on when logging in to the HPC. This is often quite small and possibly backed up. The home directory can be used for storing things like configuration files or locally installed software.\nA scratch space (e.g. /scratch/user), which is high-performance, large-scale storage. This type of storage may be private to the user or shared with a group. It is usually not backed up, so the user needs to ensure that important data are stored elsewhere. This is the main partition were data is processed from.\n\n\n\n\n\n\n\nNote\n\n\n\nHPC Filesystem\nThe separation into “home” and “scratch” storage space may not always apply to the HPC available at your institution. Also, the location of the “scratch space” will most likely differ from the example used in this course. Ask your local HPC admin to learn more about your specific setup.\nWe have a specific page demonstrating the setup of HPC servers at Cambridge University.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>HPC Introduction</span>"
    ]
  },
  {
    "objectID": "materials/01-intro.html#getting-help",
    "href": "materials/01-intro.html#getting-help",
    "title": "3  HPC Introduction",
    "section": "3.2 Getting Help",
    "text": "3.2 Getting Help\nIn most cases there will be a HPC administrator (or team), who you can reach out for help if you need to obtain more information about how your HPC is organised.\nSome of the questions you may want to ask when you start using a HPC are:\n\nwhat kind of compute nodes are available?\nwhat storage do I have access to, and how much?\nwhat job scheduler software is used, and can you give me an example submission script to get started?\nwill I be charged for the use of the HPC?\n\nAlso, it is often the case that the HPC needs some maintenance service, and you should be informed that this is happening (e.g. by a mailing list). Sometimes things stop working or break, and there may be some time when your HPC is not available while work is being done on it.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>HPC Introduction</span>"
    ]
  },
  {
    "objectID": "materials/01-intro.html#exercises",
    "href": "materials/01-intro.html#exercises",
    "title": "3  HPC Introduction",
    "section": "3.3 Exercises",
    "text": "3.3 Exercises\n\n\n\n\n\n\nExerciseExercise 1\n\n\n\n\n\n\nA PhD student wants to process some microscopy data using a python script developed by a postodoc colleague. They have instructions for how to install the necessary python packages, and also the actual python script to process the images.\nQ1. Which of the following describes the best practice for the student to organise their files/software?\nOption A:\n/scratch/user/project_name/software/ # python packages\n/scratch/user/project_name/data/     # image files\n/scratch/user/project_name/scripts/  # analysis script\nOption B:\n/home/user/software/                # python packages\n/scratch/user/project_name/data/    # image files \n/scratch/user/project_name/scripts/ # analysis script\nOption C:\n/home/user/project_name/software/ # python packages\n/home/user/project_name/data/        # image files\n/home/user/project_name/scripts/     # analysis script\nQ2. It turns out that the microscopy data were very large and compressed as a zip file. The postdoc told the student they can run unzip image_files.zip to decompress the file. Should they run this command from the login node or submit it as a job to one of the compute nodes?\nQ3. The analysis script used by the student generates new versions of the images. In total, after processing the data, the student ends up with ~1TB of data (raw + processed images). Their group still has 5TB of free space on the HPC, so the student decides to keep the data there until they finish the project. Do you agree with this choice, and why? What factors would you take into consideration in deciding what data to keep and where?\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nOption C is definitely discouraged: as /home is typically not high-performance and has limited storage, it should not be used for storing/processing data. Option A and B only differ in terms of where the software packages are installed. Typically software can be installed in the user’s /home, avoiding the need to reinstall it multiple times, in case the same software is used in different projects. Therefore, option B is the best practice in this example.\nA2.\nSince compressing/uncompressing files is a fairly routine task and unlikely to require too many resources, it would be OK to run it on the login node. If in doubt, the student could have gained “interactive” access to one of the compute nodes (we will cover this in another section).\nA3.\nLeaving the data on the HPC is probably a bad choice. Since typically “scratch” storage is not backed-up it should not be relied on to store important data. If the student doesn’t have access to enough backed-up space for all the data, they should at least back up the raw data and the scripts used to process it. This way, if there is a problem with “scratch” and some processed files are lost, they can recreate them by re-running the scripts on the raw data.\nOther criteria that could be used to decide which data to leave on the HPC, backup or even delete is how long each step of the analysis takes to run, as there may be a significant computational cost associated with re-running heavy data processing steps.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>HPC Introduction</span>"
    ]
  },
  {
    "objectID": "materials/01-intro.html#summary",
    "href": "materials/01-intro.html#summary",
    "title": "3  HPC Introduction",
    "section": "3.4 Summary",
    "text": "3.4 Summary\n\n\n\n\n\n\nTipKey Points\n\n\n\n\nA HPC consists of several computers connected in a network. Each of these computers are called a node:\nThe login nodes are the machines that we connect to and from where we interact with the HPC. These should not be used to run resource-intensive tasks.\nThe compute nodes are the high-performance machines on which the actual heavy computations run. Jobs are submitted to the compute nodes through a job scheduler.\nThe job scheduler is used to submit scripts to be run on the compute nodes.\n\nThe role of this software is to manage large numbers of jobs being submitted and prioritise them according to their resource needs.\nWe can configure how our jobs are run by requesting the adequate resources (CPUs and RAM memory).\nChoosing resources appropriately helps to get our jobs the right level of priority in the queue.\n\nThe filesystem on a HPC is often split between a small (backed) home directory, and a large and high-performance (non-backed) scratch space.\n\nThe user’s home is used for things like configuration files and local software instalation.\nThe scratch space is used for the data and analysis scripts.\nNot all HPC servers have this filesystem organisation - always check with your local HPC admin.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>HPC Introduction</span>"
    ]
  },
  {
    "objectID": "materials/02-ssh.html",
    "href": "materials/02-ssh.html",
    "title": "4  Remote Work",
    "section": "",
    "text": "4.1 Connecting to the HPC\nAll interactions with the HPC happen via the terminal. To connect to the HPC we use the program ssh. The syntax is:\nAfter running this command you will be asked for your password and after typing it you will be logged in to the HPC.\nNote that the first time you login to a server, you will be presented with a message similar to:\nIf you are confident about the security of the server you are connecting to, you can type yes. Often, the server fingerprint is sent by the HPC admins ahead of time (or available in the documentation) for you to compare and confirm you are connecting to the correct server. For example, at Cambridge, we are provided with this information on the CSD3 documentation page.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Work</span>"
    ]
  },
  {
    "objectID": "materials/02-ssh.html#connecting-to-the-hpc",
    "href": "materials/02-ssh.html#connecting-to-the-hpc",
    "title": "4  Remote Work",
    "section": "",
    "text": "ssh your-hpc-username@hpc-address\n\n\nThe authenticity of host '[192.168.1.59]:2231 ([192.168.1.59]:2231)' can't be established.\nRSA key fingerprint is SHA256:4X1kUMDOG021U52XDL2U56GFIyC+S5koImofnTHvALk.\nAre you sure you want to continue connecting (yes/no)?\n\n\nWindowsmacOSLinux\n\n\n\nMobaXtermWSLPutty\n\n\nOn Windows, if you are using the MobaXterm program, you can open a terminal as shown below. To paste text to the MobaXterm terminal you can use the right-click mouse button. The first time you right-click with your mouse on the terminal, a window will open asking what you would like to do. Select “Paste” (the default) and, from there on, every time you right-click on the terminal it will paste text from your clipboard.\n\n\n\nLogin to HPC using the MobaXterm terminal. 1) Click “Start local terminal” 2) Use the ssh program to connect to the HPC. You may get a warning if this is the first time you connect; if you trust the server, type “yes”. 3) You will then be asked for your password. Note that as you type the password nothing shows on the screen, but that’s normal. A window might open asking you whether you would like to save the password - answer “No”. 4) You will receive a login message your terminal will now indicate your HPC username and the name of the HPC server.\n\n\n\n\nTo open the terminal search for “Terminal” on your Windows apps.\nTo copy and paste text you can use the usual keyboard shortcuts Ctrl + C and Ctrl + V. Alternatively, you can use the right mouse button.\n\n\n\nLogin to HPC using the terminal. 1) Use the ssh program to connect to the HPC. You may get a warning if this is the first time you connect; if you trust the server, type “yes”. 2) You will then be asked for your password. Note that as you type the password nothing shows on the screen, but that’s normal. 3) You will receive a login message and your terminal will now indicate your HPC username and the name of the HPC server.\n\n\n\n\nAn alternative way to connect to a remote server on Windows is to use the program Putty. This is less flexible than the other two alternatives, as it doesn’t give you command-line tools for file transfer (covered in a later chapter).\n\n\n\nLogin to HPC using the Putty application. 1) Under “Host Name” type your username@hostname. 2) Click “Open”. 3) The first time you connect you get a warning if this is the first time you connect; if you trust the server, press “Accept”. 4) A terminal will open and ask for your password. Note that as you type the password nothing shows on the screen, but that’s normal. After typing your password you will be given a terminal on the remote HPC.\n\n\n\n\n\n\n\nTo open the terminal press ⌘ + space to open spotlight search. Search for “terminal” and press enter.\nTo copy and paste text you can use the usual keyboard shortcuts ⌘ + C and ⌘ + V. Alternatively, you can use the right mouse button.\n\n\n\nLogin to HPC using the terminal. 1) Use the ssh program to connect to the HPC. You may get a warning if this is the first time you connect; if you trust the server, type “yes”. 2) You will then be asked for your password. Note that as you type the password nothing shows on the screen, but that’s normal. 3) You will receive a login message and your terminal will now indicate your HPC username and the name of the HPC server.\n\n\n\n\nYou can open your terminal using the keyboard shortcut: Ctrl + Alt + T. To copy and paste text on the terminal you have to use the shortcut Ctrl + Shift + C and Ctrl + Shift + V. Alternatively, you can use the right mouse button.\n\n\n\nLogin to HPC using the terminal. 1) Use the ssh program to connect to the HPC. You may get a warning if this is the first time you connect; if you trust the server, type “yes”. 2) You will then be asked for your password. Note that as you type the password nothing shows on the screen, but that’s normal. 3) You will receive a login message and your terminal will now indicate your HPC username and the name of the HPC server.\n\n\n\n\n\n\n4.1.1 Exercise: SSH\n\n\n\n\n\n\nExerciseExercise 1\n\n\n\n\n\n\nAfter registering for a HPC account, you were sent the following information by the computing support:\n\nAn account has been created for you on our HPC.\n\nUsername: emailed separately\nPassword: emailed separately\nHost: login.hpc.cam.ac.uk\n\nYou were automatically allocated 40GB in /home/USERNAME/ (backed storage) and 1TB in /home/USERNAME/rds/hpc-work (non-backed high-performance “scratch” space for computations).\n\n\nConnect to the training HPC using ssh. (Note: when you type your password, nothing shows on the screen - that’s normal, the password is still being input.)\nTake some time to explore your home directory to identify what files and folders are in there. Can you identify and navigate to your high-performance compute directory?\nUse the commands free -h (available RAM memory) and nproc --all (number of CPU cores available) to check the capabilities of the login node of our HPC. Check how many people are logged in to the HPC login node using the command who.\n\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nTo login to the HPC we run the following from the terminal:\nssh USERNAME@HOSTNAME\nReplacing “USERNAME” by your HPC username and “HOSTNAME” with the name of the server you are accessing. After typing it, you will be prompted for your password. Note that as you type the password nothing shows on the screen - that’s normal! The password is still being input.\nA2.\nWe can get a detailed list of the files on our home directory:\nls -l\nThis will reveal that there is a shell script (.sh extension) named slurm_submit_template.sh and also a shortcut to our scratch directory, in this case /home/username/rds/. Within that directory, we have another one named hpc-work, which is the default high-performance storage we were given on this cluster.\nTherefore, to navigate to our scratch directory we can do:\ncd ~/rds/hpc-work\nRemember that ~ indicates your home directory, which in Linux filesystems is /home/USERNAME/.\nA3.\nThe main thing to consider in this question is where you run the commands from. To get the number of CPUs and memory on your computer make sure you open a new terminal and that you see something like [your-local-username@laptop: ~]$ (where “user” is the username on your personal computer and “laptop” is the name of your personal laptop). Note that this does not work on the MacOS shell (see this post for instructions to find the specs of your Mac).\nConversely, to obtain the same information for the HPC, make sure you are logged in to the HPC when you run the commands. You should see something like [your-hpc-username@login ~]$.\nTo see how many people are currently on the login node we can combine the who and wc commands:\n# pipe the output of `who` to `wc`\n# the `-l` flag instructs `wc` to count \"lines\" of its input\nwho | wc -l\nYou should notice that several people are using the same login node as you. This is why we should never run resource-intensive applications on the login node of a HPC.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotePasswordless Login\n\n\n\nTo make your life easier, you can configure ssh to login to a server without having to type your password or username. This can be done using SSH key based authentication. See this page with detailed instructions of how to create a key and add it to the remote host.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Work</span>"
    ]
  },
  {
    "objectID": "materials/02-ssh.html#editing-scripts-remotely",
    "href": "materials/02-ssh.html#editing-scripts-remotely",
    "title": "4  Remote Work",
    "section": "4.2 Editing Scripts Remotely",
    "text": "4.2 Editing Scripts Remotely\nMost of the work you will be doing on a HPC is editing script files. These may be scripts that you are developing to do a particular analysis or simulation, for example (in Python, R, Julia, etc.). But also - and more relevant for this course - you will be writing shell scripts containing the commands that you want to be executed on the compute nodes.\nThere are several possibilities to edit text files on a remote server. A simple one is to use the program Nano directly from the terminal. This is a simple text editor available on most linux distributions, and what we will use in this course.\nAlthough Nano is readily available and easy to use, it offers limited functionality and is not as user friendly as a full-featured text editor. Therefore, we also include a bonus section below introducing Visual Studio Code (VS Code for short), which is an open-source software with a wide range of functionality and several extensions, including one for working on remote servers.\n\n4.2.1 Nano\n\nTo create a file with Nano you can run the command:\nnano test.sh\nThis opens a text editor, where you can type the code that you want to save in the file. Once we’re happy with our code, we can press Ctrl+O to write our data to disk. We’ll be asked what file we want to save this to: press Enter to confirm the filename. Once our file is saved, we can use Ctrl+X to quit the editor and return to the shell.\nWe can check with ls that our new file is there.\n\n\n\nScreenshot of the command line text editor Nano. In this example, we also included !#/bin/bash in the first line of the script. This is called a shebang and is a way to inform that this script uses the program bash to run the script.\n\n\nNote that because we saved our file with .sh extension (the conventional extension used for shell scripts), Nano does some colouring of our commands (this is called syntax highlighting) to make it easier to read the code.\n\n\n4.2.2 Visual Studio Code\n\nVS Code is a fully-featured programming text editor available for all major platforms (Mac, Linux, Windows). One of the strenghts of this text editor is the wide range of extensions it offers. One of those extensions is called Remote SHH and allows us to connect to a remote computer (via ssh) and edit files as if they were on our own computer. See Data & Setup for how to install both VS Code and this extension.\nTo connect VS Code to the HPC (see image below):\n\nClick the “Open Remote Window” green button on the bottom left corner.\nClick “Connect to Host…” in the popup menu that opens.\nClick “+ Add New SSH Host…”.\nType your username and HPC hostname in the same way you do with ssh.\nSelect SSH configuration file to save this information for the future. Select the first file listed in the popup menu (a file in your user’s home under .ssh/config).\nA menu pops open on the bottom right informing the host was added to the configuration file. Click “Connect”.\nYou may be asked what kind of platform you are connecting to. HPC environments always run on Linux.\nThe first time you connect to a host you will also be asked if you trust this computer. You can answer “Continue”.\nFinally, you will be asked for your password. Once you are connected the green button on the bottom-left corner should change to indicate you are ssh’d into the HPC\nTo open a folder on the HPC, use the left-hand “Explorer” and click “Open Folder”\nType the path to the folder on the HPC from where you want to work from and press OK\n\nYou may be asked for your password again. The first time you connect to a folder you will also be asked “Do you trust the authors of the files in this folder?”, to which you can answer “Yes, I trust the authors”.\n\n\n\n\n\n\n  \n\n\nSteps to connect to a remote server with VS Code. Click the image to open a larger size.\n\n\n\nOnce you are connected to the HPC in this way, you can edit files and even create new files and folders on the HPC filesystem. You can also open a terminal within VS Code by going to the menu “Terminal &gt; New Terminal”.\n\n\n\n\n\n\nNoteTwo-factor authentication\n\n\n\nIf your HPC requires two-factor authentication, then you need to make sure to have the correct setting in the Remote-SSH extension:\n\nGo to File → Preferences → Settings\nIn the search box type “Remote SSH: Show Login Terminal”\nMake sure the option “Always reveal the SSH login terminal” is ticked.\n\nWith this option turned on, when you try to connect to the HPC, a terminal will open that will ask for your password and two-factor authentication code.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Work</span>"
    ]
  },
  {
    "objectID": "materials/02-ssh.html#summary",
    "href": "materials/02-ssh.html#summary",
    "title": "4  Remote Work",
    "section": "4.3 Summary",
    "text": "4.3 Summary\n\n\n\n\n\n\nTipKey Points\n\n\n\n\nThe terminal is used to connect and interact with the HPC.\n\nTo connect to the HPC we use ssh username@remote-hostname.\n\nNano is a text editor that is readily available on HPC systems.\n\nTo create or edit an existing file we use the command nano path/to/filename.sh.\nKeyboard shortcuts are used to save the file (Ctrl + O) and to exit (Ctrl + X).\n\nVisual Studio Code is a text editor that can be used to edit files directly on the HPC using the “Remote-SSH” extension.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Remote Work</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html",
    "href": "materials/03-slurm.html",
    "title": "5  SLURM Scheduler",
    "section": "",
    "text": "5.1 Job Scheduler Overview\nAs we briefly discussed in “Introduction to HPC”, HPC servers usually have a job scheduler software that manages all the jobs that the users submit to be run on the compute nodes. This allows efficient usage of the compute resources (CPUs and RAM), and the user does not have to worry about affecting other people’s jobs.\nThe job scheduler uses an algorithm to prioritise the jobs, weighing aspects such as:\nBased on these, the algorithm will rank each of the jobs in the queue to decide on a “fair” way to prioritise them. Note that this priority dynamically changes all the time, as jobs are submitted or cancelled by the users, and depending on how long they have been in the queue. For example, a job requesting many resources may start with a low priority, but the longer it waits in the queue, the more its priority increases.\nIn these materials we will cover a job scheduler called SLURM, however the way this scheduler works is very similar to other schedulers. The specific commands may differ, but the functionality is the same (see this document for matching commands to other job sheculers).",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html#job-scheduler-overview",
    "href": "materials/03-slurm.html#job-scheduler-overview",
    "title": "5  SLURM Scheduler",
    "section": "",
    "text": "How much time did you request to run your job?\nHow many resources (CPUs and RAM) do you need?\nHow many other jobs have you got running at the moment?",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html#submitting-a-job-with-slurm",
    "href": "materials/03-slurm.html#submitting-a-job-with-slurm",
    "title": "5  SLURM Scheduler",
    "section": "5.2 Submitting a Job with SLURM",
    "text": "5.2 Submitting a Job with SLURM\nTo submit a job to SLURM, you need to include your code in a shell script. Let’s start with a minimal example, found in our workshop data folder “slurm”.\nOur script is called simple_job.sh and contains the following code:\n#!/bin/bash\n\nsleep 60 # hold for 60 seconds\necho \"This job is running on:\"\nhostname\nWe can run this script from the login node using the bash interpreter (make sure you are in the correct directory first: cd ~/rds/hpc-work/hpc_workshop/):\nbash job_scripts/simple_job.sh\nWhich prints the output:\nThis job is running on:\nlogin-node\nTo submit the job to the scheduler we instead use the sbatch command in a very similar way:\nsbatch job_scripts/simple_job.sh\nIn this case, we are informed that the job is submitted to the SLURM queue. We can see all the jobs in the queue with:\nsqueue\nJOBID  PARTITION      NAME      USER  ST  TIME  NODES  NODELIST(REASON)\n  193   training  simple_j  particip   R  0:02      1  training-dy-t2medium-2\nThis gives a list of all the jobs running, with their “status” (ST column), which is usually:\n\nPD for a pending job, meaning the job is waiting the queue to get started.\nR for a running job, meaning the job is currently running on one of the compute nodes.\n\nBut if our job is running on a compute node, where does the output go? Instead of being printed to the terminal, the output of this script will be saved to a file. By default the file is named slurm-JOBID.out, where “JOBID” is a number corresponding to the job ID assigned to the job by the scheduler. This file will be located in the same directory where you launched the job from.\nWe can investigate the output by looking inside the file, for example cat slurm-JOBID.out.\n\n\n\n\n\n\nImportant\n\n\n\nThe first line of the shell scripts #!/bin/bash is called a shebang and indicates which program should interpret this script. In this case, bash is the interpreter of shell scripts (there’s other shell interpreters, but that’s beyond what we need to worry about here).\nRemember to always have this as the first line of your script. If you don’t, sbatch will throw an error.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html#configuring-job-options",
    "href": "materials/03-slurm.html#configuring-job-options",
    "title": "5  SLURM Scheduler",
    "section": "5.3 Configuring Job Options",
    "text": "5.3 Configuring Job Options\nAlthough the above example works, our job just ran with the default options that SLURM was configured with. Instead, we usually want to customise our job, by specifying options at the top of the script using the #SBATCH keyword, followed by the SLURM option.\nFor example, one option we may want to change in our previous script is the name of the file to where our standard output is written to. We can do this using the -o option.\nHere is how we could modify our script (you can do it using Nano or VS Code):\n#!/bin/bash\n#SBATCH -o job_logs/simple_job.log\n\nsleep 8 # hold for 8 seconds\necho \"This job is running on:\"\nhostname\nIf we now re-run the script using sbatch simple_job.sh, the output goes to a file named simple_job.log.\nThere are several other options we can specify when using SLURM, and we will encounter several more of them as we progress through the materials. Here are some of the most common ones (anything in &lt;&gt; is user input):\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\n-D &lt;path&gt;\nworking directory used for the job. This is the directory that SLURM will use as a reference when running the job.\n\n\n-o &lt;path/filename&gt;\nfile where the output that would normally be printed on the console is saved in. This is defined relative to the working directory set above.\n\n\n-A &lt;name&gt;\nbilling account. This is sometimes needed if you’re using HPC servers that charge you for their use. This information should be provided by your HPC admins.\n\n\n-p &lt;name&gt;\npartition name. See details in the following section.\n\n\n-c &lt;number&gt;\nthe number of CPUs you want to use for your job.\n\n\n-t &lt;HH:MM:SS&gt;\nthe time you need for your job to run. This is not always easy to estimate in advance, so if you’re unsure you may want to request a good chunk of time. However, the more time you request for your job, the lower its priority in the queue.\n\n\n--mem=&lt;number&gt;GB\nhow much RAM memory you want for your job in gigabytes.\n\n\n-J &lt;name&gt;\na name for the job.\n\n\n\n\n\n\n\n\n\nImportantDefault Resources\n\n\n\nIf you don’t specify any options when submitting your jobs, you will get the default configured by the HPC admins. For example, in our Cambridge HPC, the defaults you will get are:\n\n10 minutes of running time (equivalent to -t 00:10:00)\ncclake partition (equivalent to -p cclake)\n1 CPU (equivalent to -c 1)\n~3.4 GiB RAM (equivalent to --mem=3.4G)\n\n\n\n\n5.3.1 Partitions\nOften, HPC servers have different types of compute node setups (e.g. queues for fast jobs, or long jobs, or high-memory jobs, etc.). SLURM calls these “partitions” and you can use the -p option to choose which partition your job runs on. Usually, which partitions are available on your HPC should be provided by the admins.\nIt’s worth keeping in mind that partitions have separate queues, and you should always try to choose the partition that is most suited to your job.\nFor example, on the Cambridge HPC we have several partitions, here are two examples:\n\ncclake partition (default)\n\nMaximum 56 CPUs (default: 1)\nMaximum 3928 MB RAM (default: 1024)\n\ntraininglarge partition\n\nMaximum 8 CPUs (default: 1)\nMaximum 31758 MB RAM (default: 1024)",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html#getting-job-information",
    "href": "materials/03-slurm.html#getting-job-information",
    "title": "5  SLURM Scheduler",
    "section": "5.4 Getting Job Information",
    "text": "5.4 Getting Job Information\nAfter submitting a job, we may want to know:\n\nWhat is going on with my job? Is it running or has it finished?\nIf it finished, did it finish successfully, or did it fail?\nHow many resources (e.g. RAM) did it use?\nWhat if I want to cancel a job because I realised there was a mistake in my script?\n\nWe’ve already seen the squeue command to check the status of your jobs. Without any options you will get all jobs in the queue (yours and other users’), to see only your jobs you can do:\nsqueue -u &lt;user&gt;\nThis gives you information about the job’s status: PD means it’s pending (waiting in the queue) and R means it’s running on a compute node.\nTo see more information for a job (and whether it completed or failed), you can use:\nseff JOBID\nThis shows you the status of the job (running, completed, failed), how many cores it used, how long it took to run and how much memory it used. Therefore, this command is very useful to determine suitable resources (e.g. RAM, time) next time you run a similar job.\nAlternatively, you can use the sacct command, which allows displaying this and other information in a more condensed way (and for multiple jobs if you want to).\nFor example:\nsacct --format JobName,Account,State,AllocCPUs,ReqMem,MaxRSS,AveRSS,Elapsed -j JOBID\n\nJobName is the job’s name\nAccount is the account used for the job\nState gives you the state of the job\nAllocCPUs is the number of CPUs you requested for the job\nReqMem is the memory that you asked for (Mc or Gc indicates MB or GB per core; Mn or Gn indicates MB or GB per node)\nMaxRSS is the maximum memory used during the job per core\nAveRSS is the average memory used per core\nElapsed how much time it took to run your job\n\nAll the format options available with sacct can be listed using sacct -e.\nIf you forgot what your job id is, running sacct with no other options will show you information about the jobs that ran recently. If you want to know the ID of jobs that ran in a period of time, you can do:\nsacct -S 2024-01-01 -E 2024-02-01 --format=JobID,JobName,Start,End,State\nHere, -S is the start date and -E the end date of the time period you want to list jobs for. You can omit the -E option, in which case it will list all the jobs that ran up to the current date.\n\n\n\n\n\n\nNote\n\n\n\nThe sacct command may not be available on every HPC, as it depends on how it was configured by the admins.\n\n\nYou can also see more details about a job, such as the working directory and output directories, using:\nscontrol show job &lt;JOBID&gt;\nFinally, if you want to cancel a job, you can use:\nscancel &lt;JOBID&gt;\nAnd to cancel all your jobs simultaneously: scancel -u &lt;USERNAME&gt; (you will not be able to cancel other people’s jobs, so don’t worry about it).\n\n5.4.1 Exercise: Submit SLURM job\n\n\n\n\n\n\nExerciseExercise 1\n\n\n\n\n\n\nBefore starting this exercise:\n\nMake sure you are in the workshop folder (cd ~/rds/hpc-work/hpc_workshop).\nActivate a software environment needed for the exercise (we will cover the details in the Software Management chapter): mamba activate base\n\nYour prompt should now start with the prefix (base)\n\n\nIn the “analysis_scripts” directory, you will find an R script called pi_estimator.R. This script tries to get an approximate estimate for the number Pi using a stochastic algorithm.\n\n\nHow does the algorithm work?\n\nIf you are interested in the details, here is a short description of what the script does:\n\nThe program generates a large number of random points on a 1×1 square centered on (½,½), and checks how many of these points fall inside the unit circle. On average, π/4 of the randomly-selected points should fall in the circle, so π can be estimated from 4f, where f is the observed fraction of points that fall in the circle. Because each sample is independent, this algorithm is easily implemented in parallel.\n\n\n\n\nEstimating Pi by randomly placing points on a quarter circle. (Source: HPC Carpentry)\n\n\n\nIf you were running this script interactively (i.e. directly from the console), you would use the R script interpreter: Rscript analysis_scripts/pi_estimator.R. Instead, we use a shell script to submit this to the job scheduler.\n\nEdit the shell script in job_scripts/estimate_pi.sh by correcting your username in the working directory path (under #SBATCH -D). Submit the job to SLURM and check its status in the queue.\nDid your job run successfully, and how long did it take to run?\nThe number of samples used to estimate Pi can be modified using the --nsamples option of our script, defined in millions. The more samples we use, the more precise our estimate should be.\n\nAdjust your SLURM submission script to use 50 million samples (Rscript analysis_scripts/pi_estimator.R --nsamples 50), and save the job output in job_logs/estimate_pi_50M.log.\nMonitor the job status with squeue and seff JOBID. Do you find any issues? How would you fix it?\n\n\n\n\n\n\n\n\nHintHint\n\n\n\n\n\n\n\nUse seff JOBID or scontrol show job JOBID to see job details.\n\n\n\n\n\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nIn the shell script we needed to correct the path specified in the #SBATCH -D option, which defines the working directory that SLURM will run our code from. We needed to replace “FIX-YOUR-USERNAME” with our actual username.\nWe could then submit the script using sbatch job_scripts/estimate_pi.sh. And check the status of the job with squeue -u USERNAME (using our respective username).\nBecause the job runs very fast, we may not have time to see it in the queue at all. However, we can check if it ran successfully in the next step.\nA2.\nAs suggested in the hint, we can use the seff or scontrol commands to check whether our job was successful and how long it took:\nseff JOBID\nscontrol show job JOBID\nReplacing JOBID with the ID of the job we just ran.\nIf you cannot remember what the job id was, you can run sacct with no other options and it will list the last few jobs that you ran.\nSometimes it may happen that the “Memory Utilized” is reported as 0.00MB or a lower value than you would expect. That’s very odd, since for sure our script must have used some memory to do the computation. The reason is that SLURM doesn’t always have time to pick memory usage spikes, and so it reports a zero. This is usually not an issue with longer-running jobs.\nA3.\nThe modified script should look similar to this:\n#!/bin/bash\n#SBATCH -p training \n#SBATCH -D /home/USERNAME/rds/hpc-work/hpc_workshop/  # working directory\n#SBATCH -o job_logs/estimate_pi_50M.log  # standard output file\n#SBATCH -c 1        # number of CPUs. Default: 1\n#SBATCH -t 00:10:00 # time for the job HH:MM:SS.\n\n# run the script\nRscript analysis_scripts/pi_estimator.R --nsamples 50\nHowever, when we run this job, examining the output file (cat job_logs/estimate_pi_50M.log) will reveal an error indicating that our job was killed.\n/var/spool/slurmd/job02038/slurm_script: line 9:  6682 Killed                  Rscript analysis_scripts/pi_estimator.R --nsamples 50\nslurmstepd: error: Detected 1 oom-kill event(s) in StepId=2038.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.\nFurthermore, if we use seff to get information about the job, it will show State: OUT_OF_MEMORY (exit code 0).\nThis suggests that the job required more memory than we requested. We can also check this by seeing what seff reports as “Memory Utilized” and see that it exceeded the requested 1GB (although sometimes it shows much less than that, if it ran too fast and SLURM didn’t register the memory usage peak).\nTo correct this problem, we would need to increase the memory requested to SLURM, adding to our script, for example, #SBATCH --mem=3G to request 3Gb of RAM memory for the job.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html#slurm-environment-variables",
    "href": "materials/03-slurm.html#slurm-environment-variables",
    "title": "5  SLURM Scheduler",
    "section": "5.5 SLURM Environment Variables",
    "text": "5.5 SLURM Environment Variables\nOne useful feature of SLURM jobs is the automatic creation of environment variables. Generally speaking, variables are a character that store a value within them, and can either be created by us, or sometimes they are automatically created by programs or available by default in our shell.\n\n\n\n\n\n\nNoteMore about shell variables (click to view)\n\n\n\n\n\nAn example of a common shell environment variable is $HOME, which stores the path to the user’s /home directory. We can print the value of a variable with echo $HOME.\nThe syntax to create a variable ourselves is:\nVARIABLE=\"value\"\nNotice that there should be no space between the variable name and its value.\nIf you want to create a variable with the result of evaluating a command, then the syntax is:\nVARIABLE=$(command)\nTry these examples:\n# Make a variable with a path starting from the user's /home\nDATADIR=\"$HOME/rds/hpc-work/data/\"\n\n# list files in that directory\nls $DATADIR\n\n# create a variable with the output of that command\nDATAFILES=$(ls $DATADIR)\n\n\n\nWhen you submit a job with SLURM, it creates several variables, all starting with the prefix $SLURM_. One useful variable is $SLURM_CPUS_PER_TASK, which stores how many CPUs we requested for our job. This means that we can use the variable to automatically set the number of CPUs for software that support multi-processing. We will see an example in the following exercise.\nHere is a table summarising some of the most useful environment variables that SLURM creates:\n\n\n\nVariable\nDescription\n\n\n\n\n$SLURM_CPUS_PER_TASK\nNumber of CPUs requested with -c\n\n\n$SLURM_JOB_ID\nThe job ID\n\n\n$SLURM_JOB_NAME\nThe name of the job defined with -J\n\n\n$SLURM_SUBMIT_DIR\nThe working directory defied with -D\n\n\n$SLURM_ARRAY_TASK_ID\nThe number of the sub-job when running parallel arrays (covered in the Job Arrays section)\n\n\n\n\n5.5.1 Exercise: SLURM environment variables\n\n\n\n\n\n\nExerciseExercise 2\n\n\n\n\n\n\nBefore starting this exercise:\n\nMake sure you are in the workshop folder (cd ~/rds/hpc-work/hpc_workshop).\nActivate a software environment needed for the exercise (we will cover the details in the Software Management chapter): mamba activate base\n\nYour prompt should now start with the prefix (base)\n\n\nThe R script used in the previous exercise supports parallelisation of some of its internal computations. The number of CPUs used by the script can be modified using the --ncpus option. For example pi_estimator.R --nsamples 200 --ncpus 2 would use two CPUs.\n\nModify your submission script (job_scripts/estimate_pi.sh) to: \n\nUse the $SLURM_CPUS_PER_TASK variable to set the number of CPUs used by pi_estimator.R (and ensure you have set --nsamples 200 as well).\nRequest 3 CPUs and 9G of RAM memory for the job.\nBonus (optional): use echo within the script to print a message indicating the job number (SLURM’s job ID is stored in the variable $SLURM_JOB_ID).\n\nSubmit the job again but this time requesting 8 CPUs. Make a note of each job’s ID.\nCheck how much time each job took to run (using seff JOBID). Did increasing the number of CPUs shorten the time it took to run?\n\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nWe can modify our submission script in the following manner, requesting 3 CPUs and 9GB or RAM:\n\n#!/bin/bash\n#SBATCH -A TRAINING-CPU\n#SBATCH -p icelake  # name of the partition to run job on\n#SBATCH -D /home/FIX-YOUR-USERNAME/rds/hpc-work/hpc_workshop/  # working directory\n#SBATCH -o job_logs/estimate_pi_200M_3CPU.log  # standard output file\n#SBATCH -c 3        # number of CPUs. Default: 1\n#SBATCH --mem=9G    # RAM memory. Default: 1G\n#SBATCH -t 00:10:00 # time for the job HH:MM:SS. Default: 1 min\n\n# launch the Pi estimator script using the number of CPUs that we are requesting from SLURM\nRscript analysis_scripts/pi_estimator.R --nsamples 200 --ncpus $SLURM_CPUS_PER_TASK\nTo run the job each time, we modify the #SBATCH -c option, save the file and then re-submit it with sbatch job_scripts/estimate_pi.sh.\nAfter running each job we can use seff JOBID command to obtain information about how long it took to run.\nAlternatively, since we want to compare several jobs, we could also have used sacct like this:\nsacct -o JobID,elapsed -j JOBID1,JOBID2\nIn this case, it doesn’t seem that increasing the number of CPUs from 3 to 8 shortens the time the job takes to run. It is often the case that the time to run a parallelised tasks doesn’t scale linearly, which is likely because there are other computational costs to do with this kind of parallelisation (e.g. keeping track of what each parallel thread is doing).",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html#interactive-login",
    "href": "materials/03-slurm.html#interactive-login",
    "title": "5  SLURM Scheduler",
    "section": "5.6 Interactive Login",
    "text": "5.6 Interactive Login\nSometimes it may be useful to directly get a terminal on one of the compute nodes. This may be useful, for example, if you want to test some scripts or run some code that you think might be too demanding for the login node (e.g. to compress some files).\nIt is possible to get interactive access to a terminal on one of the compute nodes using the sintr command. This command takes options similar to the sbatch program, so you can request resources in the same way you would when submitting scripts.\nFor example, to access to 8 CPUs and 10GB of RAM for 1h on one of the compute nodes we would do:\nsintr -c 8 --mem=10G -p icelake -t 01:00:00 -A TRAINING-CPU\nYou may get a message saying that SLURM is waiting to allocate your request (you go in the queue, just like any other job!). Eventually, when you get in, you will notice that your terminal will indicate you are on a different node (different from the login node). You can check by running hostname.\nAfter you’re in, you can run any commands you wish, without worrying about affecting other users’ work. Once you are finished, you can use the command exit to terminate the session, and you will go back to the login node.\nNote that, if the time you requested (with the -t option) runs out, your session will be immediately killed.\n\n\n\n\n\n\nImportantUse interactive jobs ethically\n\n\n\nThe main purpose of interactive jobs is to quickly test code or to run routine tasks such as compressing/uncompressing large files. You should not use interactive jobs for your actual analysis.\nThe main reason is that interactive jobs require users to actively monitor and manage their tasks, which may not be the most efficient use of their time. This may also result in congesting the job queue, causing delays for other users with batch jobs waiting to be processed. Furthermore, batch jobs can be scheduled to run during off-peak hours, allowing users to focus on other tasks while their computations are being processed.\nFor this reason, some HPC clusters are configured to limit the time for interactive jobs (for example, at Cambridge University these are limited to 1h).",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/03-slurm.html#summary",
    "href": "materials/03-slurm.html#summary",
    "title": "5  SLURM Scheduler",
    "section": "5.7 Summary",
    "text": "5.7 Summary\n\n\n\n\n\n\nTipKey Points\n\n\n\n\nInclude the commands you want to run on the HPC in a shell script.\n\nAlways remember to include #!/bin/bash as the first line of your script.\n\nSubmit jobs to the scheduler using sbatch submission_script.sh.\nCustomise the jobs by including #SBATCH options at the top of your script (see table in the materials above for a summary of options).\n\nAs a good practice, always define an output file with #SBATCH -o. All the information about the job will be saved in that file, including any errors.\n\nCheck the status of a submitted job by using squeue -u USERNAME and seff JOBID.\nTo cancel a running job use scancel JOBID.\n\nSee this SLURM cheatsheet for a summary of the available commands.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SLURM Scheduler</span>"
    ]
  },
  {
    "objectID": "materials/04-software.html",
    "href": "materials/04-software.html",
    "title": "6  Software Management",
    "section": "",
    "text": "6.1 Using pre-installed software\nIt is very often the case that HPC admins have pre-installed several software packages that are regularly used by their users. Because there can be a large number of packages (and often different versions of the same program), you need to load the programs you want to use in your script using the module tool.\nThe following table summarises the most common commands for this tool:\nFor example, on our training HPC, you can try to run module avail to see which software is available. We can see a software called bowtie2. If we try to use this software at the moment we get an error:\nBut if we load the software first, then the command works:\nIf you echo $PATH, you will notice the installer has been added to your PATH variable (the environment variable that tells the shell where to find programs to run). Once you run module unload bowtie2/2.5.0, and then echo $PATH again, you notice the PATH variable will have been modified. This is how the Environment Modules package makes software available for you to use.\nIf a package is not available through the module command, your only option is to contact the HPC admin and ask them to install it for you. Alternatively, you can use a package manager as we show in the next section.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Software Management</span>"
    ]
  },
  {
    "objectID": "materials/04-software.html#sec-module",
    "href": "materials/04-software.html#sec-module",
    "title": "6  Software Management",
    "section": "",
    "text": "Command\nDescription\n\n\n\n\nmodule avail\nList all available packages.\n\n\nmodule avail -a -i \"pattern\"  or  module avail | grep -i \"pattern\"\nSearch the available package list that matches “pattern”. Note the second option is given as some versions of module do not support case-insensitive search (-i option).\n\n\nmodule load &lt;program&gt;\nLoad the program and make it available for use.\n\n\nmodule unload &lt;program&gt;\nUnload the program (removes it from your PATH).\n\n\n\n\nbowtie2 --version\nCommand 'bowtie2' not found, but can be installed with:\n\napt install bowtie2\nPlease ask your administrator.\n\nmodule load bowtie/2.5.0\nbowtie2 --version\n/usr/local/Cluster-Apps/bowtie/2.5.0/bowtie2-align-s version 2.5.0\n64-bit\nBuilt on login-e-12\nMon 14 Nov 12:11:12 UTC 2022\nCompiler: gcc version 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC)\nOptions: -O3 -msse2 -funroll-loops -g3 -std=c++11 -DPOPCNT_CAPABILITY -DNO_SPINLOCK -DWITH_QUEUELOCK=1\nSizeof {int, long, long long, void*, size_t, off_t}: {4, 8, 8, 8, 8, 8}",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Software Management</span>"
    ]
  },
  {
    "objectID": "materials/04-software.html#the-mamba-package-manager",
    "href": "materials/04-software.html#the-mamba-package-manager",
    "title": "6  Software Management",
    "section": "6.2 The Mamba package manager",
    "text": "6.2 The Mamba package manager\nOften you may want to use software packages that are not installed by default on the HPC. There are several ways you could manage your own software installation, but in this course we will be using the package manager Mamba, which is a successor to another package manager called Conda.\nConda and Mamba are package managers commonly used in data science, scientific computing, and bioinformatics. Conda, originally developed by Anaconda, is a package manager and environment manager that simplifies the creation, distribution, and management of software environments containing different packages and dependencies. It is known for its cross-platform compatibility and ease of use. Mamba is a more recent and high-performance alternative to Conda. While it maintains compatibility with Conda’s package and environment management capabilities, Mamba is designed for faster dependency resolution and installation, making it a better choice nowadays.\nOne of the strengths of using Mamba to manage your software is that you can have different versions of your software installed alongside each other, organised in environments. Organising software packages into environments is extremely useful, as it allows to have a reproducible set of software versions that you can use and resuse in your projects.\nFor example, imagine you are a data scientist working on a project that involves machine learning. You have two projects with different requirements (Figure 6.1):\n\nProject A: This project requires Python 3.7, NumPy 1.15, and scikit-learn 0.20, among other libraries.\nProject B: This project needs Python 3.9, the latest version of NumPy, and TensorFlow 2.0.\n\nIf you don’t use environments, you would need to install and maintain these packages globally on your system. This can lead to several issues:\n\nVersion conflicts: different projects may require different versions of the same library. For example, Project A might not be compatible with the latest NumPy, while Project B needs it.\nDependency chaos: as your projects grow, you might install numerous packages, and they could interfere with each other, causing unexpected errors or instability.\nDifficulty collaborating: sharing your code with colleagues or collaborators becomes complex because they may have different versions of packages installed, leading to compatibility issues.\n\n\n\n\n\n\n\nFigure 6.1: Illustration of Conda/Mamba environments. Each environment is isolated from the others (effectively in its own folder), so different versions of the packages can be installed for distinct projects or parts of a long analysis pipeline.\n\n\n\nEnvironments allow you to create isolated, self-contained environments for each project, addressing these issues:\n\nIsolation: you can create a separate environment for each project using tools like Conda/Mamba or virtualenv in Python. This ensures that the dependencies for one project don’t affect another.\nVersion control: you can specify the exact versions of libraries and packages required for each project within its environment. This eliminates version conflicts and ensures reproducibility.\nEase of collaboration: sharing your code and environment file (e.g., requirements.txt for Python) makes it easy for collaborators to replicate your environment and run your project without worrying about conflicts.\nSimplified maintenance: If you need to update a library for one project, it won’t impact others. You can manage environments separately, making maintenance more straightforward.\n\nIn the context of HPC clusters, another advantage of using Mamba is that the software is installed locally (by default in your home directory), without the need for admin permissions.\n\n\n\n\n\n\nNoteMamba versus Module\n\n\n\nAlthough Mamba is a great tool to manage your own software installation, the disadvantage is that the software is not compiled specifically taking into account the hardware of the HPC. This is a slightly technical topic, but the main practical consequence is that software installed by HPC admins and made available through the module system may sometimes run faster than software installed via mamba. This means you will use fewer resources and your jobs will complete faster.\n\n\n\n6.2.1 Installing Mamba\nBefore you use Mamba, you will need to install it on the HPC. If you are attending our live course, we already have Mamba installed, so you can skip this step.\nTo install Mamba, run the following commands from the terminal (this will install it in its default location in the home directory):\nwget \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh -b -p $HOME/miniforge3\nrm Miniforge3-$(uname)-$(uname -m).sh\n$HOME/miniforge3/bin/mamba shell init --shell bash\nLogout of the HPC and login again, to restart your terminal. Your shell should now start with the word (base).\nThen run the following commands:\nconda config --add channels bioconda; conda config --add channels conda-forge\nconda config --set remote_read_timeout_secs 1000\nThe software installation “recipes” used by Mamba are maintained by large communities of software developers. These communities are organised by channels, i.e. software repositories. Two popular channels are “bioconda”, which maintains bioinformatics software and “conda-forge”, which maintains several data science packages. Some of the commands we just ran add these channels to our Mamba installation, so that it looks for software in those repositories by default.\n\n\n6.2.2 Installing software with mamba\nThe command used to install and manage software is called mamba. Although we will only cover the basics in this course, it has an excellent documentation and a useful cheatsheet.\n\n\n\n\n\n\nNoteconda or mamba?\n\n\n\nSome of the documentation we point to is for conda, but as we said earlier mamba is its newer implementation, so these two commands can be used interchangeably (mostly). The easy rule-of-thumb is: whenever you see the command conda you can use mamba instead.\n\n\nThe first thing to do is to create a software environment for our project. Although this is optional (you could instead install everything in the “base” default environment), it is a good practice as it means the software versions remain stable within each project.\nTo create an environment we use:\nmamba create --name ENV\nWhere “ENV” is the name we want to give to that environment. Once the environment is created, we can install packages using:\nmamba install --name ENV PROGRAM\nWhere “PROGRAM” is the name of the software we want to install.\n\n\n\n\n\n\nNoteOrganising environments\n\n\n\nOne way to organise your software environments is to create an environment for each kind of analysis that you might be doing regularly. For example, you could have an environment named imaging with software that you use for image processing (e.g. Python’s scikit-image or the ImageMagick package) and another called deeplearn with software you use for deep learning applications (e.g. Python’s Keras).\nIn some situations (in particular in bioinformatics), software packages can have a very large number of software dependencies leading to incompatibilities across packages. In those situations, it may be best to have a separate environment for each software.\n\n\nTo search for the software packages that are available through mamba:\n\ngo to anaconda.org.\nin the search box search for a program of your choice. For example: “bowtie2”.\nthe results should be listed as CHANNEL/PROGRAM, where CHANNEL will the the source repository from where the software is available. Usually scientific/bioinformatics software is available through the conda-forge and bioconda channels.\n\nYou can specify the channel explicitly during the install command using the -c option. For example mamba install --channel CHANNEL --name ENV PROGRAM.\nLet’s see this with an example, where we create a new environment called “datasci” and install some python packages for data science work:\nmamba create --name datasci\nmamba install --name datasci --channel conda-forge numpy=1.26.4 matplotlib=3.8.3\nNote that, in this case, we were explicit in specifying the version of each software we want. This is recommended for reproducibility of analysis and can make environments more stable to manage. If you don’t specify the version you want, then Mamba will install the latest version that is compatible with your environment.\nTo see all the environments you have available, you can use:\nmamba env list\n# conda environments:\n#\nbase                  *  /home/participant36/mambaforge\ndatasci                  /home/participant36/mambaforge/envs/datasci\nIn our case it lists the base (default) environment and the newly created datasci environment. The asterisk (“*“) tells us which environment we’re using at the moment.\n\n\n6.2.3 Loading Mamba environments\nOnce your packages are installed in an environment, you can load that environment by using mamba activate ENV, where “ENV” is the name of your environment. For example, we can activate our previously created environment with:\nmamba activate datasci\nIf you chech which python executable is being used now, you will notice it’s the one from this new environment:\nwhich python\n~/mambaforge/envs/datasci/bin/python\nYou can also check that the new environment is in use from:\nmamba env list\n# conda environments:\n#\nbase                     /home/participant36/mambaforge\ndatasci               *  /home/participant36/mambaforge/envs/datasci\nAnd notice that the asterisk “*” is now showing we’re using the datasci environment.\n\n\n\n\n\n\nWarningLoading environments in shell scripts\n\n\n\nTo load environments in a shell script that is being submitted to SLURM, you need to first source a configuration file from Mamba. For example, to load the datasci environment we created, this would be the code:\n# Always add these two commands to your scripts\neval \"$(conda shell.bash hook)\"\nsource $CONDA_PREFIX/etc/profile.d/mamba.sh\n\n# then you can activate the environment\nmamba activate datasci\n\nThis is because when we submit jobs to SLURM the jobs will start in a non-interactive shell, and mamba doesn’t get automatically set. Running the source command shown will ensure mamba activate becomes available.\n\n\n\n\n6.2.4 Exercise: mamba environments\n\n\n\n\n\n\nExerciseExercise 1\n\n\n\n\n\n\nMake sure you are in the workshop folder (cd ~/rds/hpc-work/hpc_workshop).\nIn the data folder, you will find some files resulting from whole-genome sequencing individuals from the model organism Drosophila melanogaster (fruit fly). Our objective will be to align our sequences to the reference genome, using a software called bowtie2.\n\nBut first, we need to prepare our genome for this alignment procedure (this is referred to as indexing the genome). We have a file with the Drosophila genome in data/genome/drosophila_genome.fa.\n\nCreate a new Mamba environment named “bioinformatics”.\nInstall the bowtie2=2.5.3 program in your new environment.\nActivate the new environment.\nCheck that the software installed correctly by running which bowtie2 and bowtie2 --help.\nOpen the script in job_scripts/drosophila_genome_indexing.sh and edit the #SBATCH options with the word “FIXME”. Submit the script to SLURM using sbatch, check it’s progress, and whether it ran successfully. Troubleshoot any issues that may arise.\n\n\n\n\n\n\n\nHintHint\n\n\n\n\n\n\n\nThe syntax to create a new environment is: mamba create --name ENV\nGo to anaconda.org and search for “bowtie2” to confirm it is available through Mamba and which software channel it is provided from.\nThe syntax to install packages is: mamba install --channel CHANNEL-NAME --name ENVIRONMENT-NAME SOFTWARE-NAME.\n\n\n\n\n\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nTo create a new mamba environment we run:\nmamba create --name bioinformatics\nA2.\nIf we search for this software on the Anaconda website, we will find that it is available via the “bioconda” channel: https://anaconda.org/bioconda/bowtie2\nWe can install it on our environment with:\nmamba install --name bioinformatics --channel bioconda bowtie2=2.5.3\nA3.\nFirst we need to activate our environment:\nmamba activate bioinformatics\nThen, if we run bowtie2 --help, we should get the software help printed on the console.\nA4.\nWe need to fix the script to specify the correct working directory with our username (only showing the relevant line of the script):\n#SBATCH -D /home/USERNAME/rds/hpc-work/hpc_workshop\nReplacing “USERNAME” with your username.\nWe also need to make sure we activate our environment, by adding the mamba activate command, like this:\n# these lines are needed to source the mamba activate command\n# include them if you want to activate environments in your script\neval \"$(conda shell.bash hook)\"\nsource $CONDA_PREFIX/etc/profile.d/mamba.sh\n\n# activate conda environment\nmamba activate bioinformatics\nRemember that even though we may have loaded the environment on the login node, the scripts are run on a different machine (one of the compute nodes), so we need to remember to always load the mamba environment in our SLURM submission scripts.\nWe can then launch it with sbatch:\nsbatch job_scripts/drosophila_genome_indexing.sh\nWe can check the job status by using squeue -u USERNAME. And we can obtain more information by using seff JOBID or scontrol show job JOBID.\nWe should get several output files in the directory results/drosophila/genome with an extension “.bt2”:\nls results/drosophila/genome\nindex.1.bt2\nindex.2.bt2\nindex.3.bt2\nindex.4.bt2\nindex.rev.1.bt2\nindex.rev.2.bt2",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Software Management</span>"
    ]
  },
  {
    "objectID": "materials/04-software.html#containers",
    "href": "materials/04-software.html#containers",
    "title": "6  Software Management",
    "section": "6.3 Containers",
    "text": "6.3 Containers\nContainers are a technology that can be used to create and manage computational environments. A container is a lightweight, standalone executable package that contains everything needed to run a piece of software, including the operating system, libraries, and application code. Containers are isolated from the host system, meaning that they can run the same software in different environments without conflicts or interference. By using containers, researchers can ensure that their code runs consistently across different systems and platforms, without having to worry about dependencies or conflicts with other software on the host system.\nWe will focus on one of the most popular container platforms for cluster systems: Singularity. Singularity is a free and open-source computer program that performs operating-system-level virtualization also known as containerization. Singularity is also designed to create and manage isolated environments as Docker, which is another popular and widely used container platform (i.e. images created with docker can be compatible with Singularity and vice versa)*.\n\n\n\n\n\n\nNoteDocker vs singularity\n\n\n\n\n\nThere are some key differences between Docker containers and Singularity containers. The most important being the necessary permission level of the containers. Docker containers run as root by default, which means that they have full access to the host system. While this can be advantageous in some cases, it can also pose security risks, particularly in multi-user environments. Singularity, on the other hand, runs containers as non-root users by default, which can improve security and prevent unauthorized access to the host system. Singularity is specifically designed for use in HPC environments and can run on a wide variety of platforms and systems without root access.\nTL;TR:\n\nDocker is well-suited for building and distributing software across different platforms and operating systems\nSingularity is specifically designed for use in HPC environments and can provide improved security and performance in those settings.\n\n\n\n\n\n6.3.1 Singularity installation\nTypically, Singularity is pre-installed on HPC servers by the system administrators, and we recommend that you use the version installed by your system admins.\nAlthough it is possible to install it yourself (e.g. with Mamba), we have found this to be a less reliable way to setup Singularity on a HPC. This is because it requires further configuration to interact with the filesystem (in particular as we submit jobs to SLURM).\n\n\n6.3.2 Singularity images\nAlthough you can build your own Singularity images, for many popular software there are already pre-built images available from public repositories. Some popular ones are:\n\ndepot.galaxyproject.org\nSylabs\n\nFor example, let’s consider the SeqKit program, which is a toolkit for manipulating FASTA/Q files. If we search on either of those websites, we will see this software is available on both. In this case, the version on Sylabs (here) is older than the one on the Galaxy server (at the time of writing we have 2.8.0 available).\nTherefore, let’s consider the file on the Galaxy server. First, go to depot.galaxyproject.org and search for the software of interest (use Ctrl + F to find the text of interest). When you find the software and version of interest, right-click the file and click “Copy Link”. Then use that link with the singularity pull command:\n# create a directory for our singularity images\nmkdir images\n\n# download the image\nsingularity pull images/seqkit-2.8.0.sif https://depot.galaxyproject.org/singularity/seqkit%3A2.8.0--h9ee0642_0\nHere, we are saving the image file as seqkit-2.8.0.sif (.sif is the standard extension for singularity images). Once we have this image available, we are ready to run the software, which will see in practice with the exercise below.\n\n\n6.3.3 Exercise: running singularity\n\n\n\n\n\n\nExerciseExercise 2\n\n\n\n\n\n\nMake sure you are in the workshop folder (cd ~/rds/hpc-work/hpc_workshop).\nTo illustrate the use of Singularity, we will use the seqkit software to extract some basic statistics from the sequencing files in the data/drosophila directory. If you haven’t done so already, first download the container image with the commands shown above.\nThe way to run a command within a singularity container is:\nsingularity run PATH-TO-IMAGE YOUR COMMANDS HERE\n\nTest your singularity image by running the command seqkit --help within the container.\nModify the script job_scripts/seqkit_singularity.sh and add the command seqkit stats data/reads/*.fastq.gz, running inside the image container.\nSubmit this script as a job.\n\nWhere do you think the output will be saved?\nAs an optional bonus, modify the command to output the results to a file called results/fastq_stats.txt.\n\n\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nThe Singularity command to test our software is:\nsingularity run images/seqkit-2.8.0.sif seqkit --help\nThis prints the help documentation of the SeqKit software, confirming that our image is working and contains the intended software.\nWe are ready to run our analysis, and so we modify the SLURM submission script to include our intended command inside it:\n#!/bin/bash\n#SBATCH -p training  # name of the partition to run job on\n#SBATCH -D /home/YOUR-USERNAME/rds/hpc-work/hpc_workshop/  # working directory\n#SBATCH -o job_logs/seqkit.log  # standard output file\n#SBATCH -c 1        # number of CPUs. Default: 1\n#SBATCH --mem=1G    # RAM memory. Default: 1G\n#SBATCH -t 00:10:00 # time for the job HH:MM:SS. Default: 1 min\n\nsingularity run images/seqkit-2.8.0.sif seqkit stats data/reads/*.fastq.gz\n(Don’t forget to adjust the username in #SBATCH -D.)\nIn this case the output would be saved to the .log file. We could, instead, modify our command to save the output to a file using the standard &gt; redirection operator:\nsingularity run images/seqkit-2.8.0.sif seqkit stats data/reads/*.fastq.gz &gt; results/fastq_stats.txt\nThe output generated contains some basic statistics for our sequencing files:\nfile                             format  type  num_seqs  sum_len  min_len  avg_len  max_len\ndata/reads/SRR307023_1.fastq.gz  FASTQ   DNA      5,000  505,000      101      101      101\ndata/reads/SRR307023_2.fastq.gz  FASTQ   DNA      5,000  505,000      101      101      101\ndata/reads/SRR307024_1.fastq.gz  FASTQ   DNA      5,000  505,000      101      101      101\n\n... etc ...",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Software Management</span>"
    ]
  },
  {
    "objectID": "materials/04-software.html#summary",
    "href": "materials/04-software.html#summary",
    "title": "6  Software Management",
    "section": "6.4 Summary",
    "text": "6.4 Summary\n\n\n\n\n\n\nTipKey Points\n\n\n\n\nThe module tool can be used to search for and load pre-installed software packages on a HPC.\n\nThis tool may not always be available on your HPC.\n\nTo install your own software, you can use the Mamba package manager.\n\nMamba allows you to have separate “software environments”, where multiple package versions can co-exist on your system.\n\nUse mamba env create ENV to create a new software environment and mamba install -n ENV PROGRAM to install a program on that environment.\nUse mamba activate ENV to “activate” the software environment and make all the programs installed there available.\n\nWhen submitting jobs to sbatch, always remember to include source $CONDA_PREFIX/etc/profile.d/mamba.sh at the start of the shell script, followed by the mamba activate command.\n\nSoftware containers can be a reliable alternative to Mamba environments, with many pre-existing containers available at Sylabs and depot.galaxyproject.org.\nTo download a software container from public repositories, use the singularity pull command.\nTo run a command within the software container, use the singularity run command.\n\nFurther resources:\n\nSearch for Mamba packages at anaconda.org.\nLearn more about Conda from the Conda User Guide.\nConda Cheatsheet (PDF).",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Software Management</span>"
    ]
  },
  {
    "objectID": "materials/05-arrays.html",
    "href": "materials/05-arrays.html",
    "title": "7  Job Paralellisation",
    "section": "",
    "text": "7.1 Parallelising Tasks\nOne of the important concepts in the use of a HPC is parallelisation. This concept is used in different ways, and can mean slightly different things.\nA program may internally support parallel computation for some of its tasks, which we may refer to as multi-threading or multi-core processing. In this case, there is typically a single set of “input -&gt; output”, so all the parallel computations need to finish in order for us to obtain our result. In other words, there is some dependency between those parallel calculations.\nOn the other hand, we may want to run the same program on different inputs, where each run is completely independent from the previous run. In these cases we say the task is “embarrassingly parallel”. Usually, running tasks completely in parallel is faster, since we remove the need to keep track of what each task’s status is (since they are independent of each other).\nFinally, we may want to do both things: run several jobs in parallel, while each of the jobs does some internal parallelisation of its computations (multi-threading).",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Job Paralellisation</span>"
    ]
  },
  {
    "objectID": "materials/05-arrays.html#parallelising-tasks",
    "href": "materials/05-arrays.html#parallelising-tasks",
    "title": "7  Job Paralellisation",
    "section": "",
    "text": "Schematic of parallelisation.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTerminology Alert!\nSome software packages have an option to specify how many CPU cores to use in their computations (i.e. they can parallelise their calculations). However, in their documentation this you may be referred to as cores, processors, CPUs or threads, which are used more or less interchangeably to essentially mean “how many calculations should I run in parallel?”. Although these terms are technically different, when you see this mentioned in the software’s documentation, usually you want to set it as the number of CPU cores you request from the cluster.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Job Paralellisation</span>"
    ]
  },
  {
    "objectID": "materials/05-arrays.html#job-arrays",
    "href": "materials/05-arrays.html#job-arrays",
    "title": "7  Job Paralellisation",
    "section": "7.2 Job Arrays",
    "text": "7.2 Job Arrays\nThere are several ways to parallelise jobs on a HPC. One of them is to use a built-in functionality in SLURM called job arrays.\nJob arrays are a collection of jobs that run in parallel with identical parameters. Any resources you request (e.g. -c, --mem, -t) apply to each individual job of the “array”. This means that you only need to submit one “master” job, making it easier to manage and automate your analysis using a single script.\nJob arrays are created with the SBATCH option -a START-FINISH where START and FINISH are integers defining the range of array numbers created by SLURM. SLURM then creates a special shell variable $SLURM_ARRAY_TASK_ID, which contains the array number for the job being processed. Later in this section we will see how we can use some tricks with this variable to automate our analysis.\nFor now let’s go through this simple example, which shows what a job array looks like (you can find this script in the course folder job_scripts/parallel_arrays.sh):\n# ... some lines omitted ...\n#SBATCH -o job_logs/parallel_arrays_%a.log\n#SBATCH -a 1-3\n\necho \"This is task number $SLURM_ARRAY_TASK_ID\"\necho \"Using $SLURM_CPUS_PER_TASK CPUs\"\necho \"Running on:\"\nhostname\nSubmitting this script with sbatch job_scripts/parallel_arrays.sh will launch 3 jobs. The “%a” keyword is used in our output filename (-o) and will be replaced by the array number, so that we end up with three files: parallel_arrays_1.log, parallel_arrays_2.log and parallel_arrays_3.log. Looking at the output in those files should make it clearer that $SLURM_ARRAY_TASK_ID stores the array number of each job, and that each of them uses 2 CPUS (-c 2 option). The compute node that they run on may be variable (depending on which node was available to run each job).\n\n\n\n\n\n\nNote\n\n\n\nYou can define job array numbers in multiple ways, not just sequencially.\nHere are some examples taken from SLURM’s Job Array Documentation:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n-a 0-31\nindex values between 0 and 31\n\n\n-a 1,3,5,7\nindex values of 1, 3, 5 and 7\n\n\n-a 1-7:2\nindex values between 1 and 7 with a step size of 2 (i.e. 1, 3, 5 and 7)\n\n\n\n\n\n\n7.2.1 Exercise: arrays with no inputs\n\n\n\n\n\n\nExerciseExercise 1\n\n\n\n\n\n\nBefore starting this exercise:\n\nMake sure you are in the workshop folder (cd ~/rds/hpc-work/hpc_workshop).\nActivate a software environment needed for the exercise (we will cover the details in the Software Management chapter): mamba activate base\n\nYour prompt should now start with the prefix (base)\n\n\nPreviously, we used the pi_estimator.R script to obtain a single estimate of the number Pi. Since this is done using a stochastic algorithm, we may want to run it several times to get a sense of the error associated with our estimate.\n\nUse Nano to open the SLURM submission script in job_scripts/parallel_estimate_pi.sh. Adjust the #SBATCH options (where word “FIXME” appears), to run the job 10 times using a job array.\nLaunch the job with sbatch, monitor its progress and examine the output.\nBonus: combine all the output files into a single file. Should you run this operation directly on the login node, or submit it as a new job to SLURM?\n\n\n\n\n\n\n\nHintHint\n\n\n\n\n\n\nNote that the output of pi_estimator.R is now being sent to individual text files to the directory results/pi/.\n\n\n\n\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nIn our script, we need to add #SBATCH -a 1-10 as one of our options, so that when we submit this script to sbatch, it will run 10 iterations of it in parallel.\nAlso, remember to edit SLURM’s working directory with your username, at the top of the script in the #SBATCH -D option.\nA2.\nWe can launch our adjusted script with sbatch job_scripts/parallel_estimate_pi.sh. When we check our jobs with squeue -u USERNAME, we will notice several jobs with JOBID in the format “ID_1”, “ID_2”, etc. These indicate the number of the array that is currently running as part of that job submission.\nIn this case, we will get 10 output log files, each with the job array number at the end of the filename (we used the %a keyword in the #SBATCH -o option to achieve this).\nThe 10 separate estimates of Pi were written to separate text files named results/pi_estimate_1.txt, results/pi_estimate_2.txt, etc.\nA3.\nTo combine the results of these 10 replicate runs of our Pi estimate, we could use the Unix tool cat:\ncat results/pi/replicate_*.txt &gt; results/pi/combined_estimates.txt\nIf we examine this file (e.g. with less results/combined_estimates.txt) we can see it has the results of all the runs of our simulation.\nThis cat operation is not computationally demanding at all, so it makes sense to run it from the login node. In fact, submitting it to the scheduler would not be an efficient use of it.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Job Paralellisation</span>"
    ]
  },
  {
    "objectID": "materials/05-arrays.html#using-slurm_array_task_id-to-automate-jobs",
    "href": "materials/05-arrays.html#using-slurm_array_task_id-to-automate-jobs",
    "title": "7  Job Paralellisation",
    "section": "7.3 Using $SLURM_ARRAY_TASK_ID to Automate Jobs",
    "text": "7.3 Using $SLURM_ARRAY_TASK_ID to Automate Jobs\nOne way to automate our jobs is to use the job array number (stored in the $SLURM_ARRAY_TASK_ID variable) with some command-line tricks. The trick we will demonstrate here is to parse a CSV file to read input parameters for our scripts.\nFor example, in our data/ folder we have the following file, which includes information about parameter values we want to use with a tool in our next exercise.\n$ cat data/turing_model_parameters.csv\nf,k\n0.055,0.062\n0.03,0.055\n0.046,0.065\n0.059,0.061\nThis is a CSV (comma-separated values) format, with two “columns” named “f” and “k”. Let’s say we wanted to obtain information for the 2rd set of parameters, which in this case is in the 3rd line of the file (because of the column header). We can get the top N lines of a file using the head command (we pipe the output of the previous cat command):\n$ cat data/turing_model_parameters.csv | head -n 3\nThis gets us lines 1-3 of the file. To get just the information about that 2nd set of parameters, we can now pipe the output of the head command to the command that gets us the bottom lines of a file tail:\n$ cat data/turing_model_parameters.csv | head -n 3 | tail -n 1\nFinally, to separate the two values that are separated by a comma, we can use the cut command, which accepts a delimiter (-d option) and a field we want it to return (-f option):\n$ cat data/turing_model_parameters.csv | head -n 3 | tail -n 1 | cut -d \",\" -f 1\nIn this example, we use comma as a delimiter field and obtained the first of the values after “cutting” that line.\nSchematically, this is what we’ve done:\n\nSo, if we wanted to use job arrays to automatically retrieve the relevant line of this file as its input, we could use head -n $SLURM_ARRAY_TASK_ID in our command pipe above. Let’s see this in practice in our next exercise.\n\n7.3.1 Exercise: arrays with multiple inputs\n\n\n\n\n\n\nExerciseExercise 2\n\n\n\n\n\n\nThis exercise is composed of two equivalent sub-exercises.\nOne exemplifies how to automate a common bioinformatics task of mapping sequencing reads to a reference genome. It is suitable for life scientists who may want to go through a bioinformatics-flavoured example.\nThe other exercise uses a more generic simulation script, which takes as input two parameters that determine the simulation outcome. If it’s any motivation, this version of the exercise produces pretty pictures as an output. :)\nYou can choose one of the two to start with (whichever one suits your work better), and then do the other one if you also have time.\n\nBioinformaticsSimulation\n\n\nMake sure you are in the workshop folder (cd ~/rds/hpc-work/hpc_workshop).\nContinuing from our previous exercise where we prepared our Drosophila genome for bowtie2, we now want to map each of our samples’ sequence data to the reference genome.\n\nLooking at our data directory (ls hpc_workshop/data/reads), we can see several sequence files in standard fastq format. These files come in pairs (with suffix “_1” and “_2”), and we have 8 different samples. Ideally we want to process these samples in parallel in an automated way.\nWe have created a CSV file with three columns. One column contains the sample’s name (which we will use for our output files) and the other two columns contain the path to the first and second pairs of the input files. With the information on this table, we should be able to automate our data processing using a SLURM job array.\n\nUse Nano to open the SLURM submission script in job_scripts/parallel_drosophila_mapping.sh. The first few lines of the code are used to fetch parameter values from the CSV file:\n\nFix your username in #SBATCH -D.\nFix the #SBATCH -a option - this array should have as many jobs as we have samples in our CSV samplesheet.\nFix the head command further down the script. This command intends to fetch each line from the CSV samplesheet using the $SLURM_ARRAY_TASK_ID variable.\n\nLaunch the job with sbatch and monitor its progress (squeue), whether it runs successfully (scontrol show job JOBID or seff JOBID), and examine the SLURM output log files.\nCheck if you got the expected output files in the results/drosophila/mapping folder. (Note: the output files are text-based in a standard bioinformatics format called SAM.)\n\nStudy the submission script to see if you understand the code - and ask the trainers for clarifications if you are unfamiliar with some of the code we used.\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nWe fixed the code in three places:\n\nAs usual, we fixed the #SBATCH -D option to point to our home directory in the cluster.\nWe fixed the #SBATCH -a option - this array should have as many jobs as we have samples in our CSV samplesheet. We used #SBATCH -a 2-9:\n\nStarting at 2, because the parameter values start at the second line of the parameter file. And finishing at 9, because that’s the number of lines in the CSV file.\n\nWe also fixed the head command further down the script. This command intends to fetch each line from the CSV parameters file, using the $SLURM_ARRAY_TASK_ID variable.\n\nWe changed head -n FIXME to head -n $SLURM_ARRAY_TASK_ID, so that each job of the array fetches its corresponding line from the CSV file.\n\n\nA2.\nWe can submit the script with sbatch job_scripts/parallel_drosophila_mapping.sh. While the job is running we can monitor its status with squeue -u USERNAME. We should see several jobs listed with IDs as JOBID_ARRAYID format.\nBecause we used the %a keyword in our #SBATCH -o option, we will have an output log file for each job of the array. We can list these log files with ls job_logs/parallel_drosophila_mapping_*.log (using the “*” wildcard to match any character). If we examine the content of one of these files (e.g. cat job_logs/parallel_drosophila_mapping_1.log), we should only see the messages we printed with the echo commands. The actual output of the bowtie2 program is a file in [SAM](https://en.wikipedia.org/wiki/SAM_(file_format) format, which is saved into the results/drosophila/mapping folder.\nA3.\nOnce all the array jobs finish, we should have 8 SAM files in ls results/drosophila/mapping. We can examine the content of these files, although they are not terribly useful by themselves. In a typical bioinformatics workflow these files would be used for further analysis, for example SNP-calling.\n\n\n\n\n\n\nMake sure you are in the workshop folder (cd ~/rds/hpc-work/hpc_workshop).\nA PhD student is working on project to understand how different patterns, such as animal stripes and coral colonies, form in nature. They are using a type of model, first proposed by Alan Turing, which models the interaction between two components that can difuse in space and promote/inhibit each other.\n\n\nClick for more about this model\n\nTuring patterns can be generated with a type of mathematical model called a “Reaction-diffusion system”. It models two substances - A and B - that can difuse in space and interact with each other in the following way: substance A self-activates and also activates B, while B inhibits A.\n\n\n\nhttps://doi.org/10.1016/B978-0-12-382190-4.00006-1\n\n\nThis seemingly simple interaction can generate complex spatial patterns, some of which capture the diversity of patterns observed in nature. Here is a very friendly video illustrating this: https://youtu.be/alH3yc6tX98\n\nThe student has a python script that runs this model taking some input parameters and outputs an image file with the final result of the model. The two main parameters in the model are called “feed” and “kill”, and their python script accepts these as options, for example:\npython analysis_scripts/turing_pattern.py --feed 0.04 --kill 0.06 --outdir results/turing/\nThis would produce an image saved as results/turing/f0.04_k0.06.png.\nThe student has been running this script on their laptop, but it takes a while to run and they would like to try several parameter combinations. They have prepared a CSV file in data/turing_model_parameters.csv with parameter values of interest (you can look at the content of this file using cat).\nOur objective is to automate running these models in parallel on the HPC.\n\nUse Nano to open the SLURM submission script in job_scripts/parallel_turing_pattern.sh. The first few lines of the code are used to fetch parameter values from the CSV file:\n\nFix your username in #SBATCH -D.\nFix the #SBATCH -a option - this array should have as many jobs as we have parameter combinations in our CSV file.\nFix the head command further down the script. This command intends to fetch each line from the CSV parameters file, using the $SLURM_ARRAY_TASK_ID variable.\n\nLaunch the job with sbatch and monitor its progress (squeue), whether it runs successfully (scontrol show job JOBID or seff JOBID), and examine the SLURM output log files.\nExamine the output files in the results/turing/ folder. You should have several PNG files. These cannot be easily viewed on the HPC, but you can transfer them to your computer using Filezilla or the command-line (scp or rsync), as will be covered in the File Transfer section.\n\n\n\n\n\n\n\nHintHint\n\n\n\n\n\n\nThe array should have as many numbers as there are lines in our CSV file. However, make sure the array number starts at 2 because the CSV file has a header with column names.\n\n\n\n\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nA1.\nWe fixed the code in three places:\n\nAs usual, we fixed the #SBATCH -D option to point to our home directory in the cluster.\nWe fixed the #SBATCH -a option - this array should have as many jobs as we have simulation parameters in our CSV samplesheet. We used #SBATCH -a 2-5:\n\nStarting at 2, because the parameter values start at the second line of the parameter file. And finishing at 5, because that’s the number of lines in the CSV file.\n\nWe also fixed the head command further down the script. This command intends to fetch each line from the CSV parameters file, using the $SLURM_ARRAY_TASK_ID variable.\n\nWe changed head -n FIXME to head -n $SLURM_ARRAY_TASK_ID, so that each job of the array fetches its corresponding line from the CSV file.\n\n\nA2.\nWe can submit the script with sbatch job_scripts/parallel_turing_pattern.sh. While the job is running we can monitor its status with squeue -u USERNAME. We should see several jobs listed with IDs as JOBID_ARRAYID format.\nBecause we used the %a keyword in our #SBATCH -o option, we will have an output log file for each job of the array. We can list these log files with ls job_logs/parallel_turing_pattern_*.log (using the “*” wildcard to match any character). If we examine the content of one of these files (e.g. cat job_logs/parallel_turing_pattern_1.log), we should only see the messages we printed with the echo commands. The actual output of the python script is an image, which is saved into the results/turing folder.\nA3.\nOnce all the array jobs finish, we should have 5 image files in ls results/turing:\nf0.03_k0.055.png  f0.046_k0.065.png  f0.055_k0.062.png  f0.059_k0.061.png\nAs these are images, they cannot be viewed on the HPC. Instead, we can move these files to our computer as will be covered in the File Transfer section.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Job Paralellisation</span>"
    ]
  },
  {
    "objectID": "materials/05-arrays.html#summary",
    "href": "materials/05-arrays.html#summary",
    "title": "7  Job Paralellisation",
    "section": "7.4 Summary",
    "text": "7.4 Summary\n\n\n\n\n\n\nTipKey Points\n\n\n\n\nSome tools internally parallelise some of their computations, which is usually referred to as multi-threading or multi-core processing.\nWhen computational tasks are independent of each other, we can use job parallelisation to make them more efficient.\nWe can automatically generate parallel jobs using SLURM job arrays with the sbatch option -a.\nSLURM creates a variable called $SLURM_ARRAY_TASK_ID, which can be used to customise each individual job of the array.\n\nFor example we can obtain the input/output information from a simple configuration text file using some command line tricks: cat config.csv | head -n $SLURM_ARRAY_TASK_ID | tail -n 1\n\n\nFurther resources:\n\nSLURM Job Array Documentation",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Job Paralellisation</span>"
    ]
  },
  {
    "objectID": "materials/06-dependencies.html",
    "href": "materials/06-dependencies.html",
    "title": "8  Job Dependencies",
    "section": "",
    "text": "8.1 What is a job dependency?\nA job is said to have a dependency when it only starts based on the status of another job. For example, take this linear pipeline:\nwhere each script is taking as input the result from the previous script.\nWe may want to submit all these scripts to SLURM simultaneously, but making sure that script2 only starts after script1 finishes (successfully, without error) and, in turn, script3 only starts after script2 finishes (also successfully).\nWe can achieve this kind of job dependency using the SLURM option --dependency. There are several types of dependencies that can be used, some common ones being:\nWe will give examples of afterok, afternotok and singleton, which are commonly used.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Job Dependencies</span>"
    ]
  },
  {
    "objectID": "materials/06-dependencies.html#what-is-a-job-dependency",
    "href": "materials/06-dependencies.html#what-is-a-job-dependency",
    "title": "8  Job Dependencies",
    "section": "",
    "text": "script1.sh ----&gt; script2.sh ----&gt; script3.sh\n\n\n\n\n\n\n\n\n\n\nsyntax\nthe job starts after…\n\n\n\n\n--dependency=after:jobid[:jobid...]\nthe specified jobs have started\n\n\n--dependency=afterany:jobid[:jobid...]\nthe specified jobs terminated (with or without an error)\n\n\n--dependency=afternotok:jobid[:jobid...]\nthe specified jobs terminated with an error\n\n\n--dependency=afterok:jobid[:jobid...]\nthe specified jobs terminated successfully (exit code 0)\n\n\n--dependency=singleton\nother jobs with the same name and user have ended\n\n\n\n\n\n\n\nExample of a pipeline using job dependencies. Each of the first steps of the pipeline (filtering.sh) have no dependencies. The second steps of the pipeline (mapping.sh) each have a dependency from the previous job; in this case the --dependency=afterok:JOBID option is used with sbatch. The final step of the pipeline (variant_call.sh) depends on all the previous steps being completed; in this case the --dependency=singleton is used, which will only start this job when all other jobs with the same name (-J variant_pipeline) complete.\n\n\n\n\n\n\n\n\nNote\n\n\n\nDependencies and Arrays\nThe job dependency feature can be combined with job arrays to automate the running of parallel jobs as well as launching downstream jobs that depend on the output of other jobs.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Job Dependencies</span>"
    ]
  },
  {
    "objectID": "materials/06-dependencies.html#successful-run-afterok",
    "href": "materials/06-dependencies.html#successful-run-afterok",
    "title": "8  Job Dependencies",
    "section": "8.2 Successful Run: afterok",
    "text": "8.2 Successful Run: afterok\nIf we want a job to start after another one has finished successfully, we can use the afterok dependency keyword.\nLet’s take a simple example of having two scripts, one that creates a file and another that moves that file. The second script can only run successfully once the previous script has completed:\n# first script - creates a file\ntouch output_task1.txt\n# second script - moves the file\nmv output_task1.txt output_task2.txt\nTo submit the first script we do:\nsbatch task1.sh\nSubmitted batch job 221\nNow, we can submit the second job as:\nsbatch  --dependency afterok:221  task2.sh\nThis will ensure that this second job only starts once the first one ends successfully.\n\n\n\n\n\n\nNoteJob arrays and dependencies\n\n\n\nA job may depend on the completion of an array of jobs (as covered in job arrays). Because the whole array of jobs has its own job ID, we can use that with the afterok dependency. In that case, our job will start once all the sub-jobs in the array have completed successfully.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Job Dependencies</span>"
    ]
  },
  {
    "objectID": "materials/06-dependencies.html#automating-dependency-submissions",
    "href": "materials/06-dependencies.html#automating-dependency-submissions",
    "title": "8  Job Dependencies",
    "section": "8.3 Automating Dependency Submissions",
    "text": "8.3 Automating Dependency Submissions\nOne inconvenience of the --dependency=afterok:JOBID option is that we need to know the job ID before we launch the new job. For a couple of jobs as shown here this is not a big problem. But if we had a chain of several jobs, this would become quite tedious and prone to error.\nTo overcome this problem, we can create a job submission script that launches sbatch commands, and in the process captures the job numbers to feed into the dependency chain.\nTaking the two-step example above, we could write the following job submission script:\n# first task of our pipeline\n# capture JOBID into a variable\nrun1_id=$(sbatch --parsable task1.sh)\n\n# second task of our pipeline\n# use the previous variable here\nsbatch --dependency afterok:${run1_id} task2.sh\nThe trick here is to use the --parsable option to retrieve the job number from the message that sbatch produces. Usually the message looks like “Submitted batch job XXXX”. With the --parsable option, sbatch only outputs the job number itself.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Job Dependencies</span>"
    ]
  },
  {
    "objectID": "materials/06-dependencies.html#unsuccessful-run-afternotok",
    "href": "materials/06-dependencies.html#unsuccessful-run-afternotok",
    "title": "8  Job Dependencies",
    "section": "8.4 Unsuccessful Run: afternotok",
    "text": "8.4 Unsuccessful Run: afternotok\nIt may seem strange to have a dependency where we run our job if the previous one failed. However, this can be extremely useful for very long-running jobs that perform checkpoints and thus can resume from the step they stopped at before.\nThis is particularly useful if you have a maximum time limit enforced by your HPC admins (as it happens at Cambridge). This feature of “checkpoint-and-resume” may not be available in every software, but it is not uncommon for packages that require very long running times. If you’re working with one of these software, check their documentation.\nAlternatively, if you are writing your own programs that require very long running times (e.g. a long simulation), consider including a checkpoint procedure, so you can resume the job if it fails.\nLet’s consider the example in dependency/notok, where we have a SLURM script called task_with_checkpoints.sh. Let’s say that we were limited to a maximum of 1 minute per job and that our script requires around 2.5 minutes to run (of course these are ridiculously short times, but we’re only using to exemplify its use).\nFortunately, the person that wrote this program implemented a checkpoint system, so that our job resumes from the checkpoint, rather than from the beginning. Therefore, we would like to submit the job 3 times in total, but each time only running the job if the previous job has failed.\nThis would be our job submission script:\n# first submission\nrun1_id=$(sbatch --parsable task_with_checkpoints.sh)\n\n# second submission in case the first one fails\nrun2_id=$(sbatch --parsable --dependency afternotok:${run1_id} task_with_checkpoints.sh)\n\n# submit a third time in case the second fails\nrun3_id=$(sbatch --parsable --dependency afternotok:${run2_id} task_with_checkpoints.sh)\n\n# we could continue submitting more... but we should stop after some time\nIn this case, we are always submitting the same script to SLURM, but each time we only run it if the previous iteration failed. Because our script performs checkpoint-and-resume, we can be sure that our task will complete after 3 whole runs.\nSometimes you don’t know how many runs you will need for your job to complete. Hopefully, the software you are using prints some progress information to the log file, so you can check whether the task seems close to finishing or not. If it’s still far from finishing, you can add another afternotok job to the queue, and keep doing this until all your jobs have finished.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Job Dependencies</span>"
    ]
  },
  {
    "objectID": "materials/06-dependencies.html#swarm-of-dependencies-singleton",
    "href": "materials/06-dependencies.html#swarm-of-dependencies-singleton",
    "title": "8  Job Dependencies",
    "section": "8.5 Swarm of Dependencies: singleton",
    "text": "8.5 Swarm of Dependencies: singleton\nIn some cases you may have a job that depends on many previous jobs to have finished. In those cases, you can use an alternative dependency known as singleton. This type of dependency requires you to define a job name for all the jobs on which your singleton depends on.\nLet’s consider the example in the dependency/singleton folder. We have task1 and task2, which have no dependencies. However, task3 depends on both of the previous tasks to have completed (it requires both their outputs to generate its own result file).\nIn this case, we add -J JOB-NAME-OF-YOUR-CHOICE to each of these 3 SLURM scripts. Furthermore, to the tast3.sh script we add --dependency singleton, to indicate that we only want this job to start once all the other jobs with the same name have completed.\n\n\n\n\n\n\n\nNote\n\n\n\nBuilding Complex Pipelines\nAlthough the --dependency feature of SLURM can be very powerful, it can be somewhat restrictive to build very large and complex pipelines using SLURM only. Instead, you may wish to build pipelines using dedicated workflow management software that can work with any type of job scheduler or even just on a single server (like your local computer).\nThere are several workflow management languages available, with two of the most popular ones being Snakemake and Nextflow. Covering these is out of the scope for this workshop, but both tools have several tutorials and standardised workflows developed by the community.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Job Dependencies</span>"
    ]
  },
  {
    "objectID": "materials/06-dependencies.html#summary",
    "href": "materials/06-dependencies.html#summary",
    "title": "8  Job Dependencies",
    "section": "8.6 Summary",
    "text": "8.6 Summary\n\n\n\n\n\n\nTipKey Points\n\n\n\n\nJob dependencies can be used to sequentially run different steps of a pipeline.\nThe --dependency feature of SLURM can be used in different ways:\n\n--dependency=afterok:JOBID starts a job after a previous job with the specified ID finishes successfully (no error).\n--dependency=afternotok:JOBID starts a job if the specified job failed. This is useful for long-running tasks that have a “checkpoint-and-resume” feature.\n--dependency=singleton starts a job after all jobs with the same --job-name complete.\n\nTo automate the submission of jobs with dependencies we can:\n\nCapture the JOBID of a submission into a variable: JOB1=$(sbatch --parsable job1.sh)\nUse that variable to set the dependency for another job: sbatch --dependency=afterok:$JOB1 job2.sh",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Job Dependencies</span>"
    ]
  },
  {
    "objectID": "materials/07-files.html",
    "href": "materials/07-files.html",
    "title": "9  File Transfer",
    "section": "",
    "text": "9.1 Moving Files\nThere are several options to move data between your local computer and a remote server. We will cover three possibilities in this section, which vary in their ease of use.\nA quick summary of these tools is given in the table below.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>File Transfer</span>"
    ]
  },
  {
    "objectID": "materials/07-files.html#moving-files",
    "href": "materials/07-files.html#moving-files",
    "title": "9  File Transfer",
    "section": "",
    "text": "Filezilla\nSCP\nRsync\n\n\n\n\nInterface\nGUI\nCommand Line\nCommand Line\n\n\nData synchronisation\nyes\nno\nyes\n\n\n\n\n9.1.1 Filezilla (GUI)\nThis program has a graphical interface, for those that prefer it and its use is relatively intuitive.\nTo connect to the remote server (see Figure 3):\n\nFill in the following information on the top panel:\n\n\nHost: login.hpc.cam.ac.uk\nUsername: your HPC username\nPassword: your HPC password\nPort: 22\n\n\nClick “Quickconnect” and the files on your “home” should appear in a panel on right side.\nNavigate to your desired location by either clicking on the folder browser or typing the directory path in the box “Remote site:”.\nYou can then drag-and-drop files between the left side panel (your local filesystem) and the right side panel (the HPC filesystem), or vice-versa.\n\n\n\n\nExample of a Filezilla session. Arrows in red highlight: the connection panel, on the top; the file browser panels, in the middle; the transfer progress panel on the bottom.\n\n\n\n\n9.1.2 scp (command line)\nThis is a command line tool that can be used to copy files between two servers. One thing to note is that it always transfers all the files in a folder, regardless of whether they have changed or not.\nThe syntax is as follows:\n# copy files from the local computer to the HPC\nscp -r path/to/source_folder &lt;user&gt;@login.hpc.cam.ac.uk:path/to/target_folder\n\n# copy files from the HPC to a local directory\nscp -r &lt;user&gt;@login.hpc.cam.ac.uk:path/to/source_folder path/to/target_folder\nThe option -r ensures that all sub-directories are copied (instead of just files, which is the default).\n\n\n9.1.3 rsync (command line)\nThis program is more advanced than scp and has options to synchronise files between two directories in multiple ways. The cost of its flexibility is that it can be a little harder to use.\nThe most common usage is:\n# copy files from the local computer to the HPC\nrsync -auvh --progress path/to/source_folder &lt;user&gt;@login.hpc.cam.ac.uk:path/to/target_folder\n\n# copy files from the HPC to a local directory\nrsync -auvh --progress &lt;user&gt;@login.hpc.cam.ac.uk:path/to/source_folder path/to/target_folder\n\nthe options -au ensure that only files that have changed and are newer on the source folder are transferred\nthe options -vh give detailed information about the transfer and human-readable file sizes\nthe option --progress shows the progress of each file being transferred\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you specify the source directory as path/to/source_folder/ (with / at the end) or path/to/source_folder (without / at the end), rsync will do different things:\n\npath/to/source_folder/ will copy the files within source_folder but not the folder itself\npath/to/source_folder will copy the actual source_folder as well as all the files within it\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo check what files rsync would transfer but not actually transfer them, add the --dry-run option. This is useful to check that you’ve specified the right source and target directories and options.",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>File Transfer</span>"
    ]
  },
  {
    "objectID": "materials/07-files.html#summary",
    "href": "materials/07-files.html#summary",
    "title": "9  File Transfer",
    "section": "9.2 Summary",
    "text": "9.2 Summary\n\n\n\n\n\n\nTipKey Points\n\n\n\n\nTo transfer files to/from the HPC we can use Filezilla, which offers a user-friendly interface to synchronise files between your local computer and a remote server.\nTransfering files can also be done from the command line, using tools such as scp and rsync (this is the most flexible tool but also more advanced).",
    "crumbs": [
      "Slides",
      "Working on a HPC",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>File Transfer</span>"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html",
    "href": "materials/appendices/csd3.html",
    "title": "Cambridge University HPC Resources",
    "section": "",
    "text": "Registering for an Account\nThe supercomputers at Cambridge University are known as Cambridge Service for Data-Driven Discovery (CSD3). Here is a schematic of the university HPC:\nAnyone with a Raven account can have access to the HPC. There are different levels of service, but the basic one can be used for free. To get an account fill in the Research Computing Cluster Account Application Form.\nAfter your account is created, you will receive an email. Please read it carefully, as it contains instructions to set up two-factor authentication, which is necessary to use the Cambridge HPC.",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html#accessing-the-hpc",
    "href": "materials/appendices/csd3.html#accessing-the-hpc",
    "title": "Cambridge University HPC Resources",
    "section": "Accessing the HPC",
    "text": "Accessing the HPC\nOnce your account is created, you can login to the HPC with ssh CRSid@login.hpc.cam.ac.uk using your Raven password. You will also require a TOTP code (time-based one-time password), which should be setup on your phone when you create the account (see above).",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html#filesystem",
    "href": "materials/appendices/csd3.html#filesystem",
    "title": "Cambridge University HPC Resources",
    "section": "Filesystem",
    "text": "Filesystem\nThere are two main storage locations of interest available on the CSD3 HPC:\n\n/home/USERNAME is the user’s home directory. It has a 40GB quota and is backed up. This should be used for example for local software and perhaps some very generic scripts.\n/rds/user/USERNAME/hpc-work is the user’s working directory. It has a 1TB quota and is NOT backed up. More space can be purchased).\n\nWhen you login to the HPC you will notice there is a link (aka shortcut) to the rds directory. Try ls -l to see it.\nYou can see how much space you are using on your storage partitions using the command quota.",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html#file-transfer",
    "href": "materials/appendices/csd3.html#file-transfer",
    "title": "Cambridge University HPC Resources",
    "section": "File Transfer",
    "text": "File Transfer\nUsing scp and rsync work very similarly to the standard ssh command, they will request your password and TOTP code to transfer the files.\nFor Filezilla, you will need some extra configuration, which is detailed here.\n\n\n\n\n\n\nNoteTip\n\n\n\nIt can be quite tedious to have to type a TOTP every time you run scp, rsync or ssh. There is a way to reduce this somewhat, see this page of the docs.",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html#sec-software-csd3",
    "href": "materials/appendices/csd3.html#sec-software-csd3",
    "title": "Cambridge University HPC Resources",
    "section": "Software",
    "text": "Software\nThere are several software packages pre-installed on the HPC and available through the module command, as covered in Using pre-installed software. However, the latest versions of software are not always available. You can request the HPC helpdesk to install newer versions (or an entirely new software), although they may sometimes not do so, if it’s a fast-changing software.\nAlternatively, we recommend that you manage local software using Mamba, as explained in Software Management. Note that some software packages can be quite large, but the home directory on CSD3 only has 50GB. This risks running out of space in the home as you install more and more software. There are a few things we recommend to avoid this situation:\n\nIf you don’t anticipate needing to use an environment again soon (e.g. you finished a project), delete the environment using mamba env remove -n ENV_NAME.\nOccasionally remove unused packages and clear the cache using mamba clean --all. You can first run this command with the additional option --dry-run to see what would be removed, before actually removing it.\nInstall the large environment in a non-default directory using the option -p. For example, running mamba create -p ~/rds/hpc-work/condaenvs/mapping bowtie2 will install the environment in the specified directory. The disadvantage is that you then have to activate the environment with the path: mamba activate ~/rds/hpc-work/condaenvs/mapping.\n\n\nFinally, you can use containers with Singularity, which is pre-installed on the HPC (no need to load anything). Do not install your own Singularity (e.g. via Mamba), as it will not be correctly configured for the HPC filesystem.",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html#running-jobs",
    "href": "materials/appendices/csd3.html#running-jobs",
    "title": "Cambridge University HPC Resources",
    "section": "Running Jobs",
    "text": "Running Jobs\nThere are two types of nodes that you can access on CSD3:\n\nCPU-based cluster, which is suitable for most people (e.g. general bioinformatics use)\nGPU-based cluster, which is suitable for people using tools that parallelise on GPUs (e.g. deep learning applications and image processing)\n\nWe will focus on the CPU-based cluster, which is the most commonly used.\nThere are three types of partitions on the CPU nodes:\n\n\n\n\n\n\n\n\n\nPartition Name (-p)\nMax CPUs (-c)\nMax Total RAM (--mem=)\nMax RAM Per CPU (--mem-per-cpu=)\n\n\n\n\nicelake\n76\n256G\n3380M\n\n\nicelake-himem\n76\n512G\n6760M\n\n\ncclake\n56\n192G\n3420M\n\n\ncclake-himem\n56\n384G\n6840M\n\n\nsapphire\n112\n512G\n4580M\n\n\n\nYou can choose these depending on your needs (whether you require more or less memory per CPU).\n\nSubmission Script\nHere is a simple skeleton for your submission script:\n#!/bin/bash\n#SBATCH -A GROUPNAME-SL3-CPU   # account name (check with `mybalance`)\n#SBATCH -D /rds/xyz123/hpc-work/simulations  # your working directory\n#SBATCH -o job_logs/simulation.log # standard output and standard error will be saved in this file\n#SBATCH -p icelake             # or `icelake-himem` or `cclake` or `cclake-himem`\n#SBATCH -c 2                   # number of CPUs\n#SBATCH -t 01:00:00            # maximum 12:00:00 for SL3 or 36:00:00 for SL2\n\n\nDefault Resource Options\nIf you don’t specify some of the options listed above, this is the default you will get:\n\n10 minutes of running time (-t 00:10:00)\ncclake partition (-p cclake)\n1 CPU (-c 1)\n3420 MiB RAM (--mem=3420M or --mem-per-cpu=3420M)\n\n\nTip - test your jobs faster:\n#SBATCH --qos=intr option can be used when testing scripts. This will allocate a maximum of 1h to your job in the highest priority queue. Only one of these jobs is allowed to run at a time and after the 1h the job will be killed, so it should only be used for testing scripts.\n\n\n\nBallance & Billing\nThe billing on the University HPC is done by CPU-hour. Here’s some examples:\n\nYou requested 3 CPUs (-c 3) and 10 hours (-t 10:00:00). Your job only took 2 hours to finish. You are charged 3*2 = 6 hours of compute time.\nYou requested 1 CPU (-c 1) and 10000 MiB of total RAM (--mem=10G) on icelake-himem (-p icelake-himem), and the job took 1 hour to run. Because this partition provides 6760 MiB (or 6.7 GiB) per CPU, you will actually be charged for 2 CPUs, so 2*1 = 2 hours of compute time.\n\nIf you’re using a SL3 account (free), your allowance is capped. Each PI receives 200,000 CPU hours per quarter. You can check your allowance with the command mybalance.\nYou can purchase CPU hours on the SL2 service level. This service level gives you higher priority in the queue and jobs can run up to 36h (on the free SL3 the maximum running time is 12h).\n\n\nLong Jobs\nAs a standard, you are limited to a maximum of 36h for running jobs using an SL2 account (12h with SL3). Long jobs (up to 7 days) can be run on special queues, for which you need to request access. See instructions on the documentation page.",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html#additional-resources",
    "href": "materials/appendices/csd3.html#additional-resources",
    "title": "Cambridge University HPC Resources",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nUIS documentation:\n\nFilesystem\nFile transfer\nRunning jobs\nBilling policies\n\nPrice list for HPC storage\nSlack Workspace - you can use this workspace to get help from other uses of the University of Cambridge HPC.",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/csd3.html#other-university-departments",
    "href": "materials/appendices/csd3.html#other-university-departments",
    "title": "Cambridge University HPC Resources",
    "section": "Other University Departments",
    "text": "Other University Departments\nHere are some links to HPC information in other University Departments:\n\nCRUK\nSLCU\nPlant Sciences (Raven login required)",
    "crumbs": [
      "Slides",
      "Appendices",
      "Cambridge University HPC Resources"
    ]
  },
  {
    "objectID": "materials/appendices/slurm_cheatsheet.html",
    "href": "materials/appendices/slurm_cheatsheet.html",
    "title": "SLURM Quick Reference Guide",
    "section": "",
    "text": "SLURM Commands\nThis page summarises the most relevant information to work with the HPC, to be used as a quick-reference guide.\nThis is used in the examples that follow:",
    "crumbs": [
      "Slides",
      "Appendices",
      "SLURM Quick Reference Guide"
    ]
  },
  {
    "objectID": "materials/appendices/slurm_cheatsheet.html#slurm-commands",
    "href": "materials/appendices/slurm_cheatsheet.html#slurm-commands",
    "title": "SLURM Quick Reference Guide",
    "section": "",
    "text": "Command\nDescription\n\n\n\n\nsbatch simulation.sh\nsubmit script to scheduler\n\n\nsqueue -u xyz123\njobs currently in the queue\n\n\nscancel JOBID\ncancel the job with the specified ID (get the ID from the command above)\n\n\nscancel -u xyz123\ncancel all your jobs at once\n\n\nseff JOBID\nbasic information about the job\n\n\nsacct -o jobname,account,state,reqmem,maxrss,averss,elapsed -j JOBID\ncustom information about your job",
    "crumbs": [
      "Slides",
      "Appendices",
      "SLURM Quick Reference Guide"
    ]
  },
  {
    "objectID": "materials/appendices/slurm_cheatsheet.html#submission-script-template",
    "href": "materials/appendices/slurm_cheatsheet.html#submission-script-template",
    "title": "SLURM Quick Reference Guide",
    "section": "Submission Script Template",
    "text": "Submission Script Template\nAt the top of the submission shell script, you should have your #SBATCH options. Use this as a general template for your scripts:\n#!/bin/bash\n#SBATCH -A TRAINING-SL3-CPU        # account name\n#SBATCH -J my_simulation           # a job name for convenience\n#SBATCH -D /home/xyz123/rds/hpc-work/simulations  # your working directory\n#SBATCH -o job_logs/simulation.log     # standard output and standard error will be saved in this file\n#SBATCH -p skylake                 # partition\n#SBATCH -c 2                       # number of CPUs\n#SBATCH --mem=1GB                  # RAM memory\n#SBATCH -t 00:02:00                # Time for the job in HH:MM:SS",
    "crumbs": [
      "Slides",
      "Appendices",
      "SLURM Quick Reference Guide"
    ]
  }
]